# Вероятностное пространство

## Пространство элементарных исходов

[infobox title="Определение"]Пространством элементарных исходов называется множество $\Omega$, содержащее всевозможные взаимоисключающие результаты данного эксперимента. Элементы $\omega$ множества $\Omega$ называются элементарными исходами.[/infobox]

В данной лекции мы начнем с рассмотрения экспериментов, имеющих лишь конечное число исходов, тем самым $\Omega = \{\omega_1, \omega_2, \cdots, \omega_n\}$. В принципе, природа эксперимента абсолютно не важна, но важно, что количество исходов конечно.

## События и операции над ними

Пусть $\Omega$ – пространство элементарных исходов. Введем важное для теории вероятностей понятие – понятие события.

[infobox title="Cобытия"]Событием $A$ называется произвольное подмножество пространства элементарных исходов $\Omega$: $A \subset \Omega$.
[/infobox]

Так как события – это множества, то определены операции объединения событий, пересечения событий, разности событий, понятие дополнительного события. Дадим определения этим понятиям.

[infobox title="Oперации"]Пусть $\Omega$ – пространство элементарных исходов, $A, B$ – события. Тогда

1. **Объединением** событий $A$ и $B$ называют событие $A \cup B$, которое состоит из элементарных исходов, входящих либо в событие $A$, либо в $B$, то есть $A \cup B = \{\omega \in \Omega : \omega \in A\lor\omega \in B\}$.
2. **Пересечением** событий $A$ и $B$ называют событие $A \cap B$, которое состоит из элементарных исходов, входящих одновременно как в событие $A$, так и в событие $B$, то есть $A\cap B = \{\omega \in \Omega : \omega \in A \land \omega \in B\}$.
3. **Разностью** событий A и B называют событие $A\setminus B$, которое состоит из элементарных исходов, входящих в событие $A$, но не входящих в событие $B$, то есть $A \setminus B = \{\omega \in \Omega : \omega \in A \land \omega \notin B\}$.
4. **Дополнительным** событием к событию $A$ называется событие $\overline A$, которое состоит из элементарных исходов, не входящих в $A$, то есть $\overline A = \{\omega \in \Omega : \omega \notin A\}$.[/infobox]

[infobox title="Несовместные событие"]Пусть $\Omega$ – пространство элементарных исходов, а $A, B$ – события. Если $A \cap B = \emptyset$, то события $A$ и $B$ называются  **несовместными** .[/infobox]

Иными словами, несовместные событие – это те события, которые не могут произойти одновременно.

[warningbox title="множество всех событий"]Множество всех подмножеств $\Omega$, то есть множество всех событий, часто обозначают $\sum$.[/warningbox]

[warningbox title="Количество подмножеств событий"]В случае, когда множество $\Omega$ конечно и содержит $n$ элементов, множество всех его подмножеств тоже конечно и содержит $2^n$ элементов.[/warningbox]

Множество событий $\sum$ обладает следующими важными свойствами: вместе с любыми двумя событиями $A, B \in \sum$, оно содержит их объединение, пересечение, разность, дополнительные события, то есть:

1. $A \cup B \in \sum$
2. $A \cap B \in \sum$
3. $A \setminus B \in \sum$
4. $\overline A \in \sum$

[infobox title="Алгебра"]Множество $\sum$, обладающее описанными выше четырьмя свойствами, называется алгеброй (в вероятности часто алгеброй событий).
[/infobox]

## Простейшее вероятностное пространство

[infobox title="Вероятность событий"]Пусть имеется конечное пространство элементарных исходов $\Omega = \{\omega_1, \omega_2, \cdots, \omega_n\}$, $\sum$ – алгебра событий. Припишем каждому элементарному исходу $\omega_i$ число $p_i \ge 0$ (называемое вероятностью элементарного исхода $\omega_i$), потребовав, чтобы $p_1 + p_2 + \cdots + p_n = 1$. Вероятностью $P(A)$ события $A \in \sum$ называется число

$$
P(A) = \sum_{i: \omega_i \in A} p_i
$$

 где сумма берется по всем элементарным исходам, входящим в событие

$A$

. Функция

$P(\cdot) : \sum \to \mathbb R$

 называется вероятностной мерой.
[/infobox]

Итак, повторяясь, вероятностью события $A$ мы назвали число, равное сумме вероятностей всех элементарных исходов, входящих в событие $A$.

[infobox title="Вероятностное пространство"]Тройка $(\Omega, \sum, P)$, где $\Omega$ – пространство элементарных исходов, $\sum$ – алгебра событий (множество всех событий), $P$ – вероятностная мера, определенная на $\sum$, называется вероятностным пространством.[/infobox]

[successbox title="Лемма: Вероятностная мера обладает следующими свойствами"]

1. $P(\emptyset) = 0, P(\Omega) = 1$
2. $0 \le P(A) \le 1$ для любого события $A$
3. $P(A\cup B) = P(A) + P(B) - P(A\cap B)$
   1. Справедлива формула включений-исключений:
      $$
      P(\bigcup_{i=1}^n A_i) = \sum_{i=1}^n P(A_i) - \sum_{i<j} P(A_i\cap A_j) + \sum_{i<j<k} P(A_i\cap A_j \cap A_k) - \cdots + (-1)^{n-1}P(A_1 \cap A_2 \cap \cdots \cap A_n)
      $$
4. если $A \cap B = \emptyset$, то $P(A\cup B) = P(A) + P(B)$
5. $P(A \cup B) \le P(A) + P(B)$
   1. $P(\bigcup_{i=1}^n A_i) \le \sum_{i=1}^n P(A_i)$
6. $P(\overline A) = 1 - P(A)$
7. если $A \subset B$, то $P(B \setminus A) = P(B) - P(A)$
8. если $A \subset B$, то $P(A) \le P(B)$

[/successbox]

[warningbox title="Площадь"]Все эти свойства легко иллюстрируются, если в качестве событий рассматривать множества $A$ на плоскости, для которых определена площадь $P(A)$.
[/warningbox]

[infobox title="Невозможный и достоверный"]Пусть $A$ – событие. Если $A = \emptyset$, то событие называют невозможным. Если $A = \Omega$, то событие называют достоверным.
[/infobox]

## Отступление про комбинаторику

[infobox title="Выбор без возвращения с учетом порядка"]Количество различных исходов в случае выбора $k$ элементов из $n$ без возвращения с учетом порядка равно

$$
A_n^k = n\cdot (n-1)\cdot (n-2)\cdot \cdots \cdot (n-(k-1))=\frac{n!}{(n-k)!}
$$

Число $A_n^k$ часто называют числом размещений из $n$ элементов по $k$ элементов, а элементарные исходы – размещениями.

В множестве из $n$ элементов возможно ровно $n!$ перестановок.

[/infobox]

[infobox title="Выбор с возвращением и с учетом порядка"]Количество различных исходов в случае выбора $k$ элементов из $n$ с возвращением и с учетом порядка равно $n^k$.
[/infobox]

[infobox title="Выбор без возвращения и без учета порядка"]Количество различных исходов в случае выбора $k$ элементов из $n$ без возвращения без учета порядка равно

$$
C_n^k = \frac{A_n^k}{k!} = \frac{n!}{k!(n-k)!}
$$

[/infobox]

[infobox title="Выбор с возвращением и без учета порядка"]Количество различных исходов в случае выбора $k$ элементов из $n$ с возвращением и без учета порядка равно

$$
C_{n+k-1}^k
$$

[/infobox]

## Несколько примеров

[h2title]Гипергеометрическое распределение[/h2title]

Пусть из урны, содержащей $N$ шаров, среди которых $K$ красных из $N − K$ белых, выбирают наудачу без возвращения $n$ шаров. Какова вероятность события $A$, что будет выбрано ровно $k$ красных шаров и $n − k$ белых?

$$
P(A) = \frac{C_K^k\cdot C_{N-K}^{n-k}}{C_N^n}
$$

[h2title]Задача о рассеянной секретарше[/h2title]

Рассмотрим популярную задачу на применение формулы включений- исключений — задачу о рассеянной секретарше. Предположим, что имеется $n$ писем и $n$ конвертов, и каждому письму предназначается ровно один конверт. Письма по конвертам должна разложить секретарша, однако секретарша была занята и положила письма в конверты случайно, но так, чтобы в каждом конверте было ровно по одному письму. Какова вероятность того, что хотя бы одно письмо найдет своего получателя?

## Условная вероятность. Независимость

[h2title]Понятие условной вероятности[/h2title]

[infobox title="Определение"]Пусть дано вероятностное пространство. Условной вероятностью события $B$ при условии, что произошло событие $A$ в случае, когда $P(A) > 0$, называется вероятность

$$
P(B \mid A) = \frac{P(A\cap B)}{P(A)}
$$

[/infobox]

[h2title]Независимость событий[/h2title]

$$
P(B\mid A) = P(B) = \frac{P(A\cap B)}{P(A)} \Rightarrow  P(A \cap B) = P(A)\cdot P(B)
$$

[infobox title="Независимость"]События A и B называются независимыми, если

$$
P(A\cap B)=P(A)\cdot P(B)
$$

[/infobox]

[successbox title="Лемма"]

1. Пусть события $A$ и $B$ несовместны, то есть $A \cap B = \emptyset$. Тогда они независимы лишь в том случае, когда $P (A) = 0$ или $P (B) = 0$.
2. Пусть события $A, B$ независимы. Тогда независимы события $A$ и $\overline B$, $\overline A$ и $B$, $\overline A$ и $\overline B$.

[/successbox]

[h2title]Независимость в совокупности[/h2title]

[infobox title="Независимость в совокупности"]События $A_1, A_2, \cdots, A_n$ называются независимыми в совокупности, если для любого $1 \le k \le n$ и любых натуральных чисел $i_1, \cdots, i_k$ таких, что $1 \le i_1 < i_2 < \cdots < i_k \le n$ выполняется

$$
P(A_{i_1}\cap A_{i_2}\cap \cdots \cap A_{i_k}) = P(A_{i_1})\cdot P(A_{i_2})\cdot \cdots \cdot P(A_{i_k})
$$

[/infobox]

[h2title]Схема Бернулли[/h2title]

[infobox title="Схема Бернулли"]Схемой Бернулли называется последовательность независимых в совокупности испытаний, в каждом из которых возможно два исхода: успех и неудача, причем вероятность успеха в каждом испытании одна и та же и равна $p \in [0, 1]$, а вероятность неудачи – $q = 1 − p$.[/infobox]

какова вероятность события $B(n, k)$ получить ровно $0 \le k \le n$ успехов в $n$ испытаниях. Для этого рассмотрим один из благоприятных для нас исходов

$$
\omega = (У, ..., У, Н, ..., Н)
$$

который означает, что первые $k$ раз произошел успех, а остальные $n − k$ раз произошла неудача. Так как подбрасывания независимы, и, грубо говоря, $P(У) = p, P(Н) = q$, то $P(\omega) = p^kq^{n−k}$. Событие $B(n, k)$ содержит такие элементарные исходы $\omega$, у которых ровно $k$ раз встречается $У$ и ровно $n − k$ раз встречается $Н$. Все эти исходы равновероятны, события, отвечающие этим исходам, несовместны, и всего таких исходов $C_n^k$. Тем самым,

$$
P(B(n,k)) = C_n^kp^kq^{n-k}
$$

Легко и полезно заметить, что

$$
P(B(n, 0)) + P(B(n, 1)) + \cdots + P(B(n, n)) = \sum_{k=0}^n C_n^kp^kq^{n-k} = (p+q)^n = 1
$$

.

# Простейшие случайные величины

## Случайные величины

[h2title]Понятие случайной величины[/h2title]

[infobox title="Понятие случайной величины"]Пусть $\Omega$ – конечное пространство элементарных исходов. Тогда произвольная вещественнозначная функция $\xi : \Omega \to \mathbb R$ называется случайной величиной.[/infobox]

[infobox title="Распределение случайной величины"]Распределением случайной величины 𝜉 называется на- бор вероятностей, с которыми она принимает свои значения P(𝜉 = 𝑎).[/infobox]

[h2title]Совместное распределение случайных величин. Независимость.[/h2title]

[infobox title="Совместное распределение случайных величин"]Совместным распределением случайных величин $\xi$ и $\eta$ называется набор вероятностей $P(\xi = a, \eta = b)$, где числа $a$ пробегают всевозможные значения $a_1, \cdots, a_n$ случайной величины $\xi$, а числа $b$ – всевозможные значения $b_1, \cdots, b_k$ случайной величины $\eta$, причем

$$
\sum_{i=1}^n\sum_{j=1}^k P(\xi = a_i, \eta = b_j) = 1
$$

[/infobox]

Совместное распределение случайных величин часто записывают в виде таблицы.

Подобно понятию независимости событий, можно ввести понятие независимости случайных величин.

[infobox title="Понятие независимости случайных величин"]Случайные величины $\xi$ со значениями из множества $A = \{a_1, \cdots, a_n\}$ и $\eta$ со значениями из множества $B = \{b1, \cdots, b_k\}$ называются независимыми, если $P(\xi = a, \eta = b) = P(\xi = a)P(\eta = b)$ при всех $a \in A, b \in B$. [/infobox]

## Некоторые числовые характеристики случайных величин

[h2title]Медиана[/h2title]

[infobox title="Медиана"]Число $a \in \mathbb R$ называется медианой случайной величины $\xi$, если

$$
P(\xi \le a)\ge\frac{1}{2} \land P(\xi\ge a)\ge\frac{1}{2}
$$

По сути своей медиана – это такое число, что случайная величина как минимум с вероятностью $\frac{1}{2}$ не больше и не меньше нее. Ясно, что медиана всегда существует, но не всегда является единственной. Если медиана не единственна, часто в качестве медианы берут полусумму наименьшей и наибольшей возможных медиан.[/infobox]

[h2title]Математическое ожидание[/h2title]

[infobox title="Математическое ожидание"]Математическим ожиданием случайной величины $\xi$ называется число

$$
E\xi = \sum_{\omega \in \Omega} \xi(\omega)P(\omega) = \sum_{x \in \xi(\Omega)} xP(\xi = x)
$$

[/infobox]

[h2title]Свойства математического ожидания[/h2title]

[infobox title="Свойства математического ожидания"]

Математическое ожидание обладает следующими свойствами.

1. Пусть $\xi \ge 0$, тогда $E\xi \ge 0$. Иными словами, если случайная величина неотрицательна, то и ее среднее вероятностное неотрицательно.
2. $E(a\xi + b\eta) = aE\xi + bE\eta$. Иными словами, математическое ожидание линейно.
3. Пусть $\xi \ge \eta$ (это значит, что $\forall \omega \in \Omega$ выполняется $\xi(\omega) \ge \eta(\omega)$, тогда $E\xi \ge E\eta$. Иными словами, математическое ожидание монотонно.
4. $\lvert E \xi \rvert \le E \lvert \xi \rvert$. Иными словами, модуль математического ожидания не превосходит математического ожидания модуля.
5. $(E \lvert \xi\eta \rvert)^2 \le E\xi^2E\eta^2$, то есть для математического ожидания справедливо неравенство Коши-Буняковского.
6. Если $\xi, \eta$ независимы, то $E(\xi\eta) = E\xi E\eta$. Иными словами, в случае независимых случайных величин, математическое ожидание произведения равно произведению математических ожиданий.

   $$
   P(\xi = x, \eta = y) = P(\xi = x)P(\eta = y)
   $$

   $ E(\xi\eta)=\sum_{x\in\xi(\Omega), y\in\eta(\Omega)} xyP(\xi=x, \eta=y)$$=\sum_{x\in\xi(\Omega), y\in\eta(\Omega)} xyP(\xi=x)P(\eta=y)$$=\sum_{x\in\xi(\Omega)} xP(\xi=x)\sum_{y\in\eta(\Omega)} yP(\eta=y)$$=E\xi E\eta$
7. Если $\xi = const \in \mathbb R$, то $E (const) = const$.

[/infobox]

[h2title]Дисперсия, ковариация и корреляция[/h2title]

[infobox title="Дисперсия"]Дисперсией случайной величины $\xi$ называется число

$$
D\xi = E(\xi - E\xi)^2
$$

[/infobox]

[infobox title="стандартное отклонение"]Средним квадратическим отклонением или стандартным отклонением случайной величины $\xi$ называется число

$$
\sigma_\xi = \sqrt{D\xi}
$$

[/infobox]

[warningbox title="Свойства дисперсии"]Дисперсия обладает следующими свойствами:

1. Она неотрицаительна, то есть $D\xi \ge 0$.
2. Она может быть вычислена по формуле $D\xi = E\xi^2 − (E\xi)^2$.
3. Она инвариантна относительно сдвига, то есть $D(\xi + a) = D\xi$.
4. Константа из-под знака дисперсии выносится с квадратом, то есть $D(c\xi) = c^2D\xi$.
5. Если $\xi$ и $\eta$ – независимые случайные величины, то дисперсия суммы равна сумме дисперсий, то есть $D(\xi + \eta) = D\xi + D\eta$.
6. $D\xi = E(\xi^2 - 2\xi E\xi + (E\xi)^2) = E\xi^2 - E(2\xi E\xi) + (E\xi)^2 = E\xi^2 - (E\xi)^2$
7. $D(\xi+\eta) = D\xi+D\eta+2(E(\xi\eta)−E\xi E\eta)$.

[/warningbox]

[infobox title="ковариация"]Величина $E(\xi\eta) − E\xi E\eta$  называется ковариацией случайных величин $\xi$ и $\eta$ и обозначается $cov(\xi,\eta)$.[/infobox]

Прямые выкладки показывают, что ковариация может быть определена и следующим способом:

$$
cov(\xi, \eta) = E((\xi - E\xi)(\eta - E\eta))
$$

[warningbox title="Теорема"]Ковариация обладает следующими свойствами.

1. $cov(\xi, \eta)=cov(\eta, \xi)$;
2. $cov(a\xi, b\eta)=abcov(\xi, \eta)$;
3. $cov(\xi+c, \eta+d)=cov(\xi, \eta)$;
4. $cov(\xi, \xi) = D\xi$.

[/warningbox]

[infobox title="Коэффициент корреляции"]Коэффициентом корреляции двух величин $\xi$ и $\eta$ с отличными от нуля дисперсиями, называется величина

$$
\rho(\xi, \eta) = \frac{cov(\xi,\eta)}{\sqrt{D\xi}\sqrt{D\eta}}=\frac{cov(\xi,\eta)}{\sigma_\xi\sigma_\eta}
$$

[/infobox]

[successbox title="Лемма"]Коэффициент корреляции обладает следующими свойствами:

1. его абсолютное значение не превосходит единицы, то есть $\lvert \rho(\xi, \eta)\rvert \le 1$;
2. Если $\xi, \eta$ – независимы, то $\rho(\xi, \eta) = 0$;
3. $\lvert \rho(\xi, \eta)\rvert \le 1$ тогда и только тогда, когда $\xi = a\eta+b$, причем $a\cdot \rho(\xi, \eta) > 0$.
4. Доказательство немедленно следует из свойства математического ожидания

$E(\lvert \xi\eta)^2 \le E\xi^2 E\eta^2$

ведь

$$
\lvert\rho(\xi,\eta)\rvert = \frac{cov(\xi,\eta)}{\sigma_\xi, \sigma_\eta} \le \frac{E(\lvert\xi-E\xi\rvert\lvert\eta-E\eta\rvert)}{\sigma_\xi\sigma_\eta}\le\frac{\sqrt{E(\lvert\xi-E\xi)^2}\sqrt{E(\lvert\eta-E\eta\rvert)^2}}{\sigma_\xi\sigma_\eta}=1
$$

[/successbox]

[h2title]Параметры схемы Бернулли[/h2title]

Покажем, как свойства математического ожидания и дисперсии могут помочь при вычислении характеристик для схемы Бернулли. Пусть случайная величина $\xi = S_n$ показывает количество успехов в серии из $n$ испытаний схемы Бернулли с вероятностью успеха $p$ в каждом испытании. Напишем ее распределение

| $\xi$ | 0                   | 1                       | $\cdots$ | n                   |
| ------- | ------------------- | ----------------------- | ---------- | ------------------- |
| $P$   | $C_n^0p^0(1-p)^n$ | $C_n^1p^1(1-p)^{n-1}$ | $\cdots$ | $C_n^np^n(1-p)^0$ |

Если пытаться вычислять математическое ожидание, что называется, «в лоб», то придется суммировать такое выражение

$$
E\xi = \sum_{i=0}^n iC_n^ip^i(1-p)^{n-i}
$$

что является довольно сложной задачей. Поступим иначе. Представим нашу случайную величину $\xi$, как сумму 𝑛 независимых случайных величин

$$
\xi = \xi_1 + \xi_2 + \cdots + \xi_n
$$

где случайная величина $\xi_i$ принимает значение 0, если произошла неудача в $i$-ом испытании (с вероятностью $1-p$) и значение 1, если произошел успех (с вероятностью $p$). Все величины $\xi_i$ одинаково распределены и имеют ряд распределения

| $\xi_i$ | 0       | 1     |
| --------- | ------- | ----- |
| P         | $1-p$ | $p$ |

причем $E\xi_i =p, D\xi_i =p-p^2 =p(1-p)=pq$. Тем самым,

$$
E\xi = E\xi_1 + \cdots + E\xi_n = np
$$

$$
D\xi = D\xi_1 + \cdots + D\xi_n = npq
$$

## Закон больших чисел

[h2title]Неравенства Маркова и Чебышева в частном случае[/h2title]

Часто в задачах достаточно лишь оценить вероятность некоторого собы- тия. Кроме того, иногда вероятность не может быть вычислена точно. Приведем несколько удобных неравенств.

[infobox title="Неравенство Маркова"]Если $\xi \ge 0 \land t > 0$, то

$$
P(\xi \ge t) \le \frac{E\xi}{t}
$$

[/infobox]

**Доказательство.** Для понятия случайной величины, введенной нами ранее, доказательство достаточно просто. Пусть случайная величина $\xi$ имеет распределение, задаваемое таблицей

| $\xi_i$ | $a_1$ | $a_2$ | $\cdots$ | $a_n$ |
| --------- | ------- | ------- | ---------- | ------- |
| P         | $p_1$ | $p_2$ | $\cdots$ | $p_n$ |

Тогда

$$\begin{aligned}
E\xi = \sum_{i=1}^n a_ip_i = \sum_{i: a_i<t}a_ip_i + \sum_{i: a_i\ge t}a_ip_i \ge \sum_{i: a_i\ge t}a_ip_i \ge \sum_{i: a_i\ge t}t\cdot p_i\\
= t\cdot\sum_{i: a_i\ge t}p_i = t\cdot P(\xi\ge t)
\end{aligned}$$

Таким образом,

$$
P(\xi \ge t) \le \frac{E\xi}{t}
$$

[infobox title="Неравенство Чебышёва"]

$$
P((\xi - E\xi)^2 \ge t) \le \frac{D\xi}{t}, t>0
$$


$$
P(\lvert \xi - E\xi \rvert \ge t) \le \frac{D\xi}{t^2}, t>0
$$
[/infobox]

**Доказательство.** Положим $\eta = (\xi - E\xi)^2 \ge 0$. Для нее справедливо неравенство Маркова, то есть
$$

P(\eta \ge t) \le \frac{E\eta}{t}

$$
Так как $E\eta = E(\xi-E\xi)^2=D\xi$, то первое неравенство доказано. Для доказательства второго неравенства достаточно заметить, что
$$

P(\lvert \xi - E\xi \rvert \ge t) = P((\xi - E\xi)^2 \ge t^2)

$$
[h2title]Индикаторы множеств[/h2title]

[infobox title="Индикатор"]Индикатором события $A$ называется функция $I(A)$, которая равна 1, если событие 𝐴 произошло, и 0 иначе.[/infobox]

[successbox title="Лемма Справедливы следующие свойства"]

1. $I(A \cap B) = I(A)I(B)$
2. $I(A \cup B) = I(A)+I(B)-I(A)I(B)$
3. $EI(A)=P(A)$

[/successbox]

[h2title]Неравенства Маркова и Чебышева[/h2title]

Часто в задачах достаточно лишь оценить вероятность некоторого события. Кроме того, иногда вероятность не может быть вычислена точно. Приведем несколько удобных неравенств.

[infobox title="Неравенство Маркова"]Если $\xi \ge 0$ и $t > 0$, то
$$

P(\xi\ge t)\le\frac{E\xi}{t}

$$
[/infobox]

**Доказательство.** Рассмотрим событие $A = \{\omega \in \Omega : \xi(\omega) \ge t\}$, тогда $1 = I(A)+I(\overline A)$. Кроме того, так как $\xi \ge 0$, то
$$

\xi = \xi\cdot I(A) + \xi\cdot I(\overline A) \ge \xi \cdot I(A)\ge t\cdot I(A)

$$
. Пользуясь свойствами математического ожидания, получим
$$

E\xi \ge tE I(A)=tP(A) \Rightarrow P(A)\le\frac{E\xi}{t}

$$
[infobox title="Неравенство Чебышёва"]
$$

P((\xi - E\xi)^2 \ge t) \le \frac{D\xi}{t}, t>0

$$


$$

P(\lvert \xi - E\xi \rvert \ge t) \le \frac{D\xi}{t^2}, t>0

$$
[/infobox]

**Доказательство.** Положим $\eta = (\xi - E\xi)^2 \ge 0$. Для нее справедливо неравенство Маркова, то есть
$$

P(\eta \ge t) \le \frac{E\eta}{t}

$$
Так как $E\eta = E(\xi-E\xi)^2=D\xi$, то первое неравенство доказано. Для доказательства второго неравенства достаточно заметить, что
$$

P(\lvert \xi - E\xi \rvert \ge t) = P((\xi - E\xi)^2 \ge t^2)

$$
[successbox title="Лемма"]Пусть $a > 0$. Случайная величина $\xi$ лежит в интервале $(E\xi − a\sqrt{D\xi}, E\xi + a\sqrt{D\xi})$ с вероятностью не меньшей, чем
$$

\frac{a^2-1}{a^2}

$$
Случайная величина $\xi$ лежит в интервале $(E\xi − 3\sqrt{D\xi}, E\xi + 3\sqrt{D\xi})$ с вероятностью не меньшей, чем $\frac{8}{9}$.[/successbox]

[h2title]Закон больших чисел[/h2title]

**Закон больших чисел для схемы Бернулли**

В этом пункте мы обсудим закон больших чисел только на примере схемы Бернулли. Пусть $S_n$ – количество успехов в $n$  испытаниях схемы Бернулли. Мы можем записать, что
$$

S_n = \xi_1 + \xi_2 + \cdots + \xi_n

$$
где $\xi_k$ принимает значение 0, если при $k$-ом испытании произошла неудача и $\xi_k$ принимает значение 1, если при $k$-ом испытании произошел успех. Как уже было вычислено ранее, $ES_n = np, DS_n = npq$. Но тогда
$$

E(\frac{S_n}{n})=p, D(\frac{S_n}{n}=\frac{npq}{n^2})=\frac{pq}{n}

$$
Согласно неравенству Чебышёва и тому, что
$$

pq=p(1-p)=\frac{1}{4}-(p-\frac{1}{2})^2\le\frac{1}{4}

$$
получим
$$

P(\lvert\frac{S_n}{n}-p\rvert\ge\varepsilon) \le \frac{D(\frac{S_n}{n})}{\varepsilon^2}=\frac{pq}{\varepsilon^2 n}\le\frac{1}{4n\varepsilon^2} \rightarrow 0 (n\to +\infty)

$$
Тем самым, вероятность того, что среднее значение количества успехов при 𝑛 подбрасываниях отклонилось от вероятности успеха при одном подбрасывании боле, чем на $\varepsilon$, стремится к нулю, при $n\to+\infty$. Кроме того, мы получаем явную оценку сверху для фиксированного $\varepsilon$:
$$

P(\lvert\frac{S_n}{n}-p\rvert\ge\varepsilon)\le\frac{p(1-p)}{n\varepsilon^2}

$$
[infobox title="Закон больших чисел Чебышёва"]Пусть имеется по- следовательность $\xi_1, \xi_2, \cdots, \xi_n$ попарно независимых и одинаково распре- деленных случайных величин. Тогда
$$

\forall \varepsilon > 0, P(\lvert\frac{\xi_1 + \xi_2 + \cdots + \xi_n}{n}-E\xi_1\rvert\ge\varepsilon) \to 0(n\to+\infty)

$$
[/infobox]

Итак, закон больших чисел утверждает, что в случае попарно независимых и одинаково распределенных случайных величин, вероятность того, что их среднее арифметическое отклоняется от математического ожидания, стремится к нулю с ростом $n$.

Последнее условие часто записывают в более общей форме (в нашем случае, так как случайные величины одинаково распределены, то их математические ожидания одинаковы)
$$

\forall \varepsilon > 0, P(\lvert\frac{\xi_1 + \xi_2 + \cdots + \xi_n}{n}-\frac{E\xi_1 + E\xi_2 + \cdots + E\xi_n}{n}\rvert\ge\varepsilon) \to 0(n\to+\infty)

$$
## Предельные теоремы для схемы Бернулли

[h2title]Теорема Пуассона[/h2title]

Схема Бернулли обладает достаточно существенным недостатком: вычисления вероятностей $C_n^kp^k(1-p)^{n-k}$ довольно трудоемки. Особенно, когда приходится вычислять суммы со слагаемыми такого вида.

[infobox title="Теорема Пуассона"]Пусть имеется последовательность схем Бернулли, причем $n\to\infty, p_n\cdot n \sim \lambda < 0$, где $n$ – количество испытаний в схеме Бернулли, $p_n$ – вероятность успеха в схеме Бернулли с $n$ испытаниями. Тогда
$$

\lim_{n\to\infty}P(B(n,k))=\frac{\lambda^k}{k!}e^{-\lambda}, k\in\mathbb N \cup \{0\}

$$
[/infobox]

как оценить погрешность?

[infobox title="Уточненная теорема Пуассона"]Пусть $A\in\mathbb N \cup \{0\}, np=\lambda$. Тогда
$$

\left|\sum_{k\in A}P(B(n,k))-\sum_{k\in A}\frac{\lambda^k}{k!}e^{-\lambda}\right| < min(p,np^2)

$$
[/infobox]

[h2title]Локальная теорема Муавра-Лапласа[/h2title]

[infobox title="Локальная теорема Муавра-Лапласа"]Пусть $S_n$ – количество успехов в серии из $n$ испытаний схемы Бернулли с вероятностью успеха $p$ в каждом испытании,
$$

x=\frac{k-np}{\sqrt{npq}}=\frac{k-ES_n}{\sqrt{DS_n}}

$$
и $k\in\mathbb N \cup \{0\}$ меняется так, что существует число $M$ , что $\lvert x \rvert \le M$ сразу при всех $n \in \mathbb N$. Тогда
$$

P(S_n=k)\sim\frac{1}{\sqrt{npq}}\cdot\frac{1}{\sqrt{2\pi}}e^{\frac{-x^2}{2}}, n\to\infty

$$
[/infobox]

[h2title]Интегральная теорема Муавра-Лапласа[/h2title]

Интегральная теорема Муавра-Лапласа, как уже отмечалось, является частным случаем центральной предельной теоремы, которая будет подробно изучена в дальнейшем.

[infobox title="标题内容"]Пусть $S_n$ – количество успехов в серии из $n$ испытаний схемы Бернулли с вероятностью успеха $p$ в каждом испытании. Тогда
$$

\lim_{n\to+\infty}P\left(a\le\frac{S_n-np}{\sqrt{npq}}\le b\right)=\frac{1}{\sqrt{2\pi}}\int_a^b e^{\frac{-x^2}{2}}dx

$$
причем сходимость равномерна по $a < b$.[/infobox]

Иначе теорема может быть записана следующим образом:
$$

\lim_{n\to+\infty}P\left(a\le\frac{S_n-ES_n}{\sqrt{DS_n}}\le b\right)=\frac{1}{\sqrt{2\pi}}\int_a^b e^{\frac{-x^2}{2}}dx

$$
Иными словами, при $a=-b<0$ она устанавливает вероятность (при $n \to \infty$) попадания величины $S_n$ в интервал
$$

(ES_n-b\sqrt{DS_n}, ES_n+b\sqrt{DS_n})

$$
Обозначим
$$

\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^x e^{\frac{-x^2}{2}}d

$$
В задачах часто требуется найти $P(A\le S_n\le B)$. Тогда при больших значениях $n$ можно записать
$$

P(A\le S_n\le B) \approx \left(\Phi\left(\frac{B-np}{\sqrt{npq}}\right)-\Phi\left(\frac{A-np}{\sqrt{npq}}\right)\right)

$$
[infobox title="Уточнение интегральной теоремы Муавра-Лапласа"]Справедлива оценка
$$

\left| P\left(\frac{S_n-np}{\sqrt{npq}}\in [a,b]\right)-\frac{1}{\sqrt{2\pi}}\int_a^b e^{\frac{-x^2}{2}}dx\right|<\frac{1}{pq\sqrt{n}}

$$
[/infobox]

Однако, из полученных оценок можно понять, когда и какую теорему применять: Пуассона или интегральную теорему Муавра-Лапласа. Можно сформулировать следующее достаточно популярное «правило»: если $n$ велико, а $np$ «сравнимо с единицей», применяем теорему Пуассона; если же при этом и величина $np$ велика, – теорему Муавра–Лапласа.

# Общее понятие вероятностного пространства

## Геометрическая вероятность

[h2title]Определение геометрической вероятности[/h2title]

[infobox title="Наводящее определение"]Пусть имеются отрезки $L$ и $l$, причем $l\subset L$. Вероятность того, что случайно выбранная точка отрезка $L$ принадлежит отрезку $l$, равна

$$
P(l)=\frac{length(l)}{length(L)}
$$

Пусть $\Omega \subset \mathbb R^m, A \subset \Omega$. Вероятность того, что случайно выбранная точка из $\Omega$ принадлежит множеству $A$, равна

$$
P(\cdot \in A)=\frac{\lambda(A)}{\lambda(\Omega)}
$$

[/infobox]

## Общее определение вероятностного пространства

Этот пункт является в большей мере теоретическим. Мы дадим общее определение события, вероятности события и вероятностного пространства.

[h2title]$\sigma$-алгебра событий[/h2title]

[infobox title="$\\sigma$ -алгебра"]

Система подмножеств $\sum$ пространства элементарных исходов $\Omega$ называется $\sigma$-алгеброй, если:

1. $\emptyset \in \sum$ (пустое множество входит в $\sum$);
2. Если $A \in \sum$, то и $\overline A \in \sum$ (вместе с каждым множеством $A$, входящим в $\sum$, дополнение $A$ тоже входит в $\sum$);
3. Если $A_1, \cdots, A_n, \cdots \in \sum$, то и

   $$
   \bigcup_{i=1}^\infty A_i \in \sum
   $$

   Иными словами, вместе с последовательностью множеств, принадлежащих $\sum$, объединение этих множеств тоже принадлежит $\sum$.

[/infobox]

Отметим классические примеры $\sigma$-алгебр подмножеств множества $\Omega$.

**Тривиальная 𝜎-алгебра** Одна из крайностей – $\sigma$- алгебра $\sum$, состоящая из двух множеств: $\sum = \{ \emptyset, \Omega\}$. Такую $\sigma$-алгебру часто называют тривиальной.

[successbox title="Лемма"]Пусть $\sum$ – $\sigma$-алгебра подмножеств $\Omega, A, B \in \sum$, тогда

1. $\Omega \in \sum$
2. $A\cup B\in\sum$
3. $A\cap B\in\sum$
4. $A\setminus B \in\sum$
5. Если $A_1, \cdots, A_n, \cdots \in \sum$, то и
   $$
   \bigcap_{i=1}^\infty A_i \in \sum
   $$

[/successbox]

**Доказательство.** Доказательства моментально следуют из правил теории множеств.

1. Так как $\emptyset \in \sum$ (свойство 1 в определении), то $\Omega = \overline\emptyset\in\sum$ (свойство 2 в определении).
2. Это свойство является частным случаем свойства 3 в определении. Достаточноположить $A_1=A, A_2=B, A_3=A_4=\cdots=\emptyset$.
3. Это свойство немедленно следует из равенства $A\cap B = \overline{\overline A \cup \overline B}$.
4. Это свойство немедленно следует из равенства $A\setminus B = A \cap \overline B$, предыдущего свойства и того, что $\overline B \in \sum$.
5. Это свойство следует из равенств
   $$
   \bigcap_{i=1}^\infty A_i = \overline{\bigcup_{i=1}^\infty \overline{A_i}}
   $$

[info]Пусть дано пространство элементарных исходов $\Omega$ и $\sigma$-алгебра выделенных подмножеств $\sum$. Событием называется произвольный элемент $\sigma$-алгебры $\sum$.[/info]

[h2title]Вероятностная мера и вероятностное пространство[/h2title]

Покажем, как вводится вероятностная мера, заданная на $\sigma$-алгебре, согласно аксиоматике Колмогорова.

[infobox title="Аксиоматика Колмогорова"]Вероятностной мерой $P$, заданной на $\sigma$-алгебре $\sum$ выделенных подмножеств $\Omega$, называется такая функция $P:\sum\to[0,1]$, что

1. $P(\emptyset)=0$
2. $P(\Omega)=1$
3. Пусть $A_1,\cdots,A_n,\cdots \in \sum, A = \bigcup_{i=1}^\infty A_i, A_i\cap A_j = \emptyset$ при $i\neq j$, тогда
   $$
   P(A)=P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i)
   $$

[/infobox]

Поясним введенное определение. Во-первых, вероятность – это число в диапазоне от 0 до 1. Первое условие утверждает, что вероятность невозможного события ($\emptyset$) равна нулю, а второе, что вероятность достоверного события ($\Omega$), то есть события, что что-нибудь да произойдет, равна единице (это условие часто называют условием нормировки). Третье же условие означает, что если целое разбить на непересекающиеся части, то вероятность целого складывается из вероятностей частей (частей может быть и счетное число).

[infobox title="Вероятностное пространство"]Тройка $(\Omega, \sum, P)$, где $\Omega$ – некоторое множество (называемое нами пространством элементарных исходов), $\sum$ – $\sigma$-алгебра выделенных подмножеств $\Omega$, и $P$ – вероятностная мера, заданная на $\sum$, называется вероятностным пространством.[/infobox]

[successbox title="Лемма"]

Пусть $(\Omega, \sum, P)$ – вероятностное пространство, $A, B \in \sum$, тогда:

1. Если $A \subset B$, то $P(A) \le P(B)$;
2. $0\le P(A)\le1$;
3. Если $A \subset B$, то $P(B\setminus A) = P(B)-P(A)$;
4. $P(A\cup B)=P(A)+P(B)−P(A\cap B)$;
5. $P(\overline A) = 1 − P(A)$;
6. Пусть $A_1, \cdots, A_n,\cdots \in \sum$, тогда
   $$
   P\left(\bigcup_{i=1}^\infty A_i\right) \le \sum_{i=1}^\infty P(A_i)
   $$
7. Пусть $A_1, \cdots, A_n \in \sum$, тогда
   $$
   P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^n P(A_i) - \sum_{i<j} P(A_i\cap A_j) + \sum_{i<j<k}P(A_i\cap A_j \cap A_k) + \cdots + (-1)^{n-1} P(A_1\cap A_2\cap\cdots\cap A_n)
   $$

[/successbox]

[h2title]Условная вероятность, независимость и независимость в совокупности[/h2title]

[infobox title="Понятие условной вероятности в общем случае"]Пусть дано вероятностное пространство $(\Omega, \sum, P)$. Условной вероятностью события $B$ при условии, что произошло событие $A$ в случае, когда $P(A)>0$, называется вероятность $P(B|A)=\frac{P(A\cap B}{P(A)}$
[/infobox]

[infobox title="Понятие независимости в общем случае"]События $A$ и $B$ называются независимыми, если

$$
P(A\cap B) = P(A)P(B)
$$

.[/infobox]

Часто приходится рассматривать не одно, два, а куда больше событий. Для них, как мы знаем, вводится понятие независимости в совокупности.

[infobox title="Независимость в совокупности в общем случае"]События $A_1, A_2, \cdots, A_n$ называются независимыми в совокупности, если для любого $1\le k \le n$ и любых натуральных чисел $i_1, \cdots, i_k$ таких, что $1\le i_1 < i_2 < \cdots < i_k \le n$ выполняется

$$
P(A_{i_1}\cap A_{i_2}\cap\cdots\cap A_{i_k}) = P(A_{i_1})P(A_{i_2})\cdot\cdots\cdot P(A_{i_k})
$$

[/infobox]

## Случайные величины и их распределения

[h2title]Понятие случайной величины[/h2title]

[infobox title="Понятие случайной величины"]Функция $\xi : \Omega \to \mathbb R$ называется случайной величиной, если для любого $a \in \mathbb R$ множество $\{\omega \in \Omega: \xi(\omega)<a\}$ является событием, то есть принадлежит $\sum$.[/infobox]

На самом деле слушатель, уставший на этом моменте от теоретических тон- костей, может немного расслабиться и считать, что любое подмножество $\Omega$ является событием. В этом случае можно считать, что любая функция $\xi : \Omega \to \mathbb R$ является случайной величиной (на практике это обычно проблем не вызывает). Как мы знаем, последнее утверждение, например, верно, когда $\Omega$ конечно или счетно (в этих случаях $\sigma$-алгеброй можно считать множество всех подмножеств $\Omega$).

[successbox title="Лемма"]Пусть $\xi$ – случайная величина, тогда для любых чисел $a,b\in\mathbb R$ справедливо

1. $\{\omega \in \Omega: \xi(\omega)\le a\} \in \sum$;
2. $\{\omega \in \Omega: \xi(\omega)> a\} \in \sum$;
3. $\{\omega \in \Omega: \xi(\omega)\ge a\} \in \sum$
4. Если $I$ – отрезок $[a, b]$, полуинтервал $[a, b)$ или $(a, b]$, интервал $(a,b)$, луч $(a,+\infty), (−\infty,a), [a,+\infty)$ или $(−\infty,a]$, то $\{\omega \in \Omega: \xi(\omega)\in I\} \in \sum$.

[/successbox]

[h2title]Функция распределения случайной величины[/h2title]

[infobox title="Функция распределения случайной величины"]Функцией распределения случайной величины $\xi$ называется функция

$$
F_\xi(x) = P(\xi < x) = P(\{\omega \in \Omega: \xi(\omega)< x\})
$$

[/infobox]

Заметим, что так как $\xi$ является случайной величиной, то для любого $x\in\mathbb R$ множество $\{\omega \in \Omega: \xi(\omega)< x\}$ является событием, а значит вероятность этого события определена и определение функции распределения корректно.

Отметим свойства функции распределения, которые интуитивно совершенно понятны.

[successbox title="Основные свойства функции распределения"]Функция распределения $F_\xi(x)$ случайной величины $\xi$ обладает следующими свойствами:

1. $F_\xi(x)$ не убывает, то есть

   $$
   если\ x_1 < x_2,\ то\ F_\xi(x_1) \le F_\xi(x_2)
   $$

   .
2. $lim_{x\to-\infty} F_\xi(x) = 0$.
3. $lim_{x\to+\infty} F_\xi(x) = 1$
4. Функция распределения непрерывна слева, то есть для каждого $x_0\in\mathbb R$ выполняется

   $$
   \lim_{x\to x_0-0}F_\xi(x) = F(x_0)
   $$

[/successbox]

[infobox title="важная обратная теорема"]Пусть функция $F(x)$ удовлетворяет четырем пунктам предыдущей теоремы, тогда существует вероятностное пространство $(\Omega, \sum, P)$ и случайная величина $\xi$, определенная на нем, что $F(x)=F_\xi(x)$, то есть функция $F$ является функцией распределения некоторой случайной величины.[/infobox]

[infobox title="Дополнительные свойства функции распределения"]Пусть $F_\xi(x)$ – функция распределения случайной величины $\xi$, тогда:

1. $P(\xi=x_0)=F_xi(x_0+x)-F_\xi(x_0)$.
2. $P(a\le\xi<b)=F_\xi(b)-F_\xi(a)$.

[/infobox]

# Типы распределений случайных величин

## Распределения случайных величин

[h2title]Дискретное распределение[/h2title]

[infobox title=""]Говорят, что случайная величина $\xi$, заданная на вероятностном пространстве $\Omega, \sum, P$, имеет дискретное распределение, если множество ее значений не более чем счетно.[/infobox]

Пусть множество значений случайной величины есть множество чисел $a_1, a_2, \cdots, a_n, \cdots$ Тогда, очевидно,

$$
\sum_i P(\xi = a_i)=1
$$

 где верхний индекс суммирования может быть как конечным (если множество значений случайной величины конечно, что мы видели ранее), так и бесконечным. Как и в простейшем случае, с дискретной случайной величи- ной часто связывают таблицу (теперь, может быть, бесконечную) или ряд распределения

| $\xi$ | $a_1$        | $a_2$        | $\cdots$ | $a_n$        | $\cdots$ |
| ------- | -------------- | -------------- | ---------- | -------------- | ---------- |
| $P$   | $P(\xi=a_1)$ | $P(\xi=a_2)$ | $\cdots$ | $P(\xi=a_n)$ | $\cdots$ |

Легко понять, что вероятность того, что случайная величина $\xi$, имеющая дискретное распределение, попадет в некоторое множество $A \subset \mathbb R$, может быть вычислена, как

$$
P(\xi \in A) = \sum_{i:a_i\in A}P(\xi = a_i)
$$

Из описанных примеров виден общий принцип построения функции распределения для дискретной случайной величины $\xi$. Пусть случайная величина задана своим рядом распределения

| $\xi$ | $a_1$ | $a_2$ | $\cdots$ | $a_n$ | $\cdots$ |
| ------- | ------- | ------- | ---------- | ------- | ---------- |
| $P$   | $p_1$ | $p_2$ | $\cdots$ | $p_n$ | $\cdots$ |

$$
F_\xi(x) = P(\xi < x) = \sum_{i:a_i<x}P(\xi=a_i) = \left\{\begin{aligned}
&0, &x\le a_1\\
&p_1, &a_1 < x \le a_2\\
&p_1+p_2, &a_2 < x \le a_3\\
&p_1+p_2+p_3, &a_3 < x \le a_4\\
&\cdots, &\cdots\\
&p_1+p_2+\cdots+p_n, &a_n < x \le a_{n+1}\\
&\cdots, &\cdots\\
\end{aligned}\right.
$$

---

**Вырожденное распределение** Говорят, что случайная величина $\xi$ имеет вырожденное распределение, и пишут $\xi \sim I_{x_0}$, если существует число $x_0 \in \mathbb R$ такое, что $P(\xi = x_0)=1$. Ряд распределения такой случайной величины имеет вид

| $\xi$ | $x_0$ |
| ------- | ------- |
| $P$   | $1$   |

$$
F_\xi(x) = P(\xi < x) = \left\{\begin{aligned}&0, &x\le x_0\\&1, &x > x_0\end{aligned}\right.
$$

---

**Распределение Бернулли** Говорят, что случайная величина $\xi$ имеет распределение Бернулли, и пишут $\xi \sim B_p$, если она принимает всего два значения 0 и 1, причем $P(\xi=1)=p, P(\xi=0)=1-p=q$. Выпишем ряд распределения:

| $\xi$ | $0$   | $1$ |
| ------- | ------- | ----- |
| $P$   | $1-p$ | $p$ |

$$
F_\xi(x) = P(\xi < x) = \left\{\begin{aligned}&0, &x\le 0\\&1-p, &0 < x \le 1\\&1, &x>1\end{aligned}\right.
$$

---

**Биномиальное распределение** Говорят, что случайная величина $\xi$ имеет биномиальное распределение, и пишут $\xi \sim Bin(n,p), p\in (0,1), n\in\mathbb N$, если она принимает значения $0,1,2,\cdots,n$ с вероятностями

$$
P(\xi=k)=C_n^kp^k(1-p)^{n-k}, k\in\{0,1,\cdots,n\}
$$

 Таблица распределения для случайной величины, имеющей биномиальное распределение, имеет вид

| $\xi$ | $0$       | $1$                   | $\cdots$ | $n-1$                     | $n$   |
| ------- | ----------- | ----------------------- | ---------- | --------------------------- | ------- |
| $P$   | $(1-p)^n$ | $C_n^1p^1(1-p)^{n-1}$ | $\cdots$ | $C_n^{n-1}p^{n-1}(1-p)^1$ | $p^n$ |

---

**Геометрическое распределение** Говорят, что случайная величина имеет геометрическое распределение, и пишут $\xi \sim G_p, p \in (0,1)$, если она принимает значения $1,2,3,\cdots,n,\cdots$ с вероятностями

$$
P(\xi = k)=(1-p)^{k-1}p, k \in \mathbb N
$$

 Таблица распределения имеет вид

| $\xi$ | $1$ | $2$      | $\cdots$ | $n$            | $\cdots$ |
| ------- | ----- | ---------- | ---------- | ---------------- | ---------- |
| $P$   | $p$ | $(1-p)p$ | $\cdots$ | $(1-p)^{n-1}p$ | $\cdots$ |

Отметим, что свое название геометрическое распределение получило из-за того, что значения вероятностей представляют собой геометрическую прогрессию со знаменателем $(1-p)$ и первым членом $p$. Кроме того, совершенно ясно, что случайная величина, имеющая геометрическое распределение, показывает номер первого успешного испытания в схеме Бернулли.

---

**Распределение Пуассона** Говорят, что случайная величина имеет распределение Пуассона, и пишут $\xi \sim \Pi_\lambda, \lambda > 0$, если она принимает значения $0,1,2,3,\cdots,n,\cdots$ с вероятностями

$$
P(\xi = k)=\frac{\lambda^k}{k!}e^{-\lambda}, k\in\{0,1,2,3,\cdots,n,\cdots\}
$$

. Проверим, что введенное нами «распределение» действительно является распределением, а именно покажем, что

$$
\sum_{k=0}^\infty P(\xi=k)=1
$$

. Имеем,

$$
\sum_{k=0}^\infty P(\xi=k)=\sum_{k=0}^\infty\frac{\lambda^k}{k!}e^{-\lambda}=e^{-\lambda}\sum_{k=0}^\infty\frac{\lambda^k}{k!} = e^{-\lambda}\cdot e^{\lambda} = 1
$$

 так как получившийся ряд – нее что иное, как ряд Маклорена для экспоненты

$$
\sum_{k=0}^\infty \frac{\lambda^k}{k!}=e^\lambda
$$

[h2title]Абсолютно непрерывные распределения, примеры[/h2title]

До сих пор мы рассматривали исключительно дискретные случайные величины, и у слушателя может возникнуть неверное представление о том, что других распределений в природе нет. На самом деле, дискретное распределение – это одна из двух **крайностей** в распределениях. Другая крайность – это так называемое абсолютно непрерывное распределение, которое мы и рассмотрим.

[infobox title="Абсолютно непрерывное распределение"]Говорят, что случайная величина $\xi$ имеет абсолютно непрерывное распределение, если существует такая неотрицательная функция $f_\xi (x): \mathbb R \to \mathbb R$, что

$$
F_\xi (x) = P(\xi < x)=\int_{-\infty}^x f_\xi(t)dt
$$

Функция $f_\xi (x)$ называется плотностью вероятности случайной величины $\xi$.[/infobox]

Проведем аналогию со случаем дискретной случайной величины. Ясно, что абсолютно непрерывная величина получена в некотором смысле «предельным переходом» от дискретной, что особенно хорошо видно из рассмотрения пары соотношений (как обычно, сумма меняется на интеграл):

$$
F_\xi(x)=P(\xi<x)=\int_{-\infty}^xf_\xi(t)dt\leftrightarrow  F_\xi(x)=P(\xi<x)=\sum_{i: a_i < x} P(\xi=a_i)
$$

Кроме того, так как $\lim_{x\to +\infty}F_\xi(x)=1$, то $\int_{-\infty}^{+\infty}f_\xi(t)dt=1$. В дискретном случае было равенство вида $\sum_{i}^{x\to+\infty}P(\xi=a_i)=1$. Тем самым, мы снова получаем пару «связанных» соотношений

$$
\int_{-\infty}^{+\infty}f_\xi(t)dt = 1 \leftrightarrow \sum_i P(\xi=a_i)=1
$$

Отметим некоторые важные свойства, присущие абсолютно непрерывной случайной величине.

[successbox title="Лемма"]Пусть $\xi$ имеет абсолютно непрерывное распределение, тогда:

1. Интеграл от плотности по всей оси равен единице, то есть

   $$
   \int_{-\infty}^{+\infty}f_\xi(t)dt=1
   $$
2. Плотность у случайной величины $\xi$ не единственна: при изменении ее значений в конечном или счетном числе точек, результат интегрирования не изменится.
3. Функция распределения $F_\xi(x)$ непрерывна на $\mathbb R$.
4. Если $f_\xi(x)$ непрерывна в точке $x_0$, то $F'_\xi(x_0)=f_\xi(x_0)$.
5. Вероятность того, что случайная величина примет какое-либо конкретное значение $x_0$ равна нулю, то есть $P(\xi = x_0)=0$.
6. Вероятность попадания случайной величины $\xi$ в произвольный промежуток $I$ (отрезок, интервал, полуинтервал, луч) вычисляется по формуле

   $$
   P(\xi\in I)=\int_If_\xi(t)dt
   $$
7. В терминах функции распределения последнее свойство может быть записано, как

   $$
   P(a < \xi < b)=P(a \le \xi < b)=P(a < \xi \le b)=P(a \le \xi \le b) = F_\xi(b)-F_\xi(a), -\infty \le a < b \le + \infty
   $$

   Конечно, в случаях, когда $a,b$ – не числа, понимается соответствующий предел.

Четвертый пункт теоремы, говорящий, что в случае непрерывности $f_\xi$ выполняется равенство $F'_\xi = f_\xi$, в том числе устанавливает способ нахождения плотности, если случайная величина имеет абсолютно непрерывное распределение. Если же последнее заранее неизвестно, то нужно быть аккуратным[/successbox]

дифференцируя функцию распределения всегда нужно про- верить: получили ли мы плотность.

---

[infobox title="Равномерное распределение"]Говорят, что случайная величина $\xi$ имеет равномерное распределение на отрезке $[a,b]$ и пишут $\xi \sim U_{a,b}$, если ее плотность имеет вид

$$
f_\xi(x) = \left\{\begin{aligned}&\frac{1}{b-a}, &x\in [a,b]\\&0, &x\notin[a,b]\end{aligned}\right.
$$

[/infobox]

Легко видеть, что

$$
\int_{-\infty}^{+\infty}f_\xi(t)dt=\int_a^b\frac{dt}{b-a}=1
$$

Вычислим функцию распределения такой величины. Так как плотность задана кусочно, то резонно рассмотреть три случая:

$$
F_\xi(x)=\left\{\begin{aligned}&\int_{-\infty}^xf_\xi(t)dt, &x\le a\\&\int_{-\infty}^af_\xi(t)dt + \int_a^xf_\xi(t)dt, &x\in(a,b]\\&\int_{-\infty}^af_\xi(t)dt+\int_a^bf_\xi(t)dt+\int_b^xf_\xi(t)dt, &a>b\\\end{aligned}\right.
$$

$$
=\left\{\begin{aligned}&\int_{-\infty}^x 0dt,&x\le a\\&\int_{-\infty}^a0dt+\int_a^x\frac{dt}{b-a}, &x\in(a,b]\\&\int_{-\infty}^a0dt+\int_a^b\frac{dt}{b-a}+\int_b^x0dt, &x>b\end{aligned}\right.
$$

$$
=\left\{\begin{aligned}&0, &x\le a\\&\frac{x-a}{b-a}, &x\in(a,b]\\&1,&x>b\end{aligned}\right.
$$

Из вида функции распределения равномерно распределенной случайной величины $\xi$ еще раз следует аналогия рассматриваемого распределения и геометрической вероятности. Если 𝑥 попадает в отрезок $[a,b]$, то вероятность попасть в отрезок $A=[a,x]$ (то есть $F_\xi(x)$, так как вероятность оказаться на луче $(-\infty, a)$ равна нулю) пропорциональна длине этого отрезка, и равна

$$
P(\cdot \in A)=\frac{\lambda(A)}{\lambda([a,b])}=\frac{x-a}{b-a}
$$

---

Следующее распределение в некоторым смысле является непрерывным аналогом распределения Пуассона.

[infobox title="Показательное распределение"]Говорят, что случайная величина $\xi$ имеет показательное распределение с параметром $\lambda > 0$ и пишут $\xi \sim Exp_\lambda$, если ее плотность имеет вид

$$
f_\xi(x)=\left\{\begin{aligned}&0,&x<0\\&\lambda e^{-\lambda x}, & x\ge 0\end{aligned}\right.
$$

[/infobox]

Функция распределения случайной величины $\xi$ легко вычисляется и задается соотношением

$$
F_\xi(x)=\left\{\begin{aligned}&0,&x\le 0\\&1 - e^{-\lambda x}, & x > 0\end{aligned}\right.
$$

---

[infobox title="Нормальное распределение"]Говорят, что случайная величина $\xi$ имеет нормальное (гауссовское) распределение с параметрами $a \in \mathbb R, \sigma^2$, и пишут $\xi \sim N_{a, \sigma^2}$, если ее плотность имеет вид

$$
f_\xi(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-a)^2}{2\sigma^2}}
$$

[/infobox]

[infobox title="понятие стандартного нормального распределения"]Нормальное распределение с параметрами $a=0,\sigma^2=1$, то есть распределение $N_{0,1}$, называют стандартным нормальным. Ясно, что плотность стандартного нормального распределения имеет вид

$$
f_\xi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$

[/infobox]

Функция распределения нормального распределения, ввиду важности
последнего, обозначается особым образом:

$$
F_\xi(x)=\Phi_{a,\sigma^2}=\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^xe^{-\frac{(t-a)^2}{2\sigma^2}}dt
$$

 не выражается в элементарных функциях и затабулирована (ее значения можно найти в таблицах). Точнее, затабулирована функция распределения стандартного нормального распределения, но с помощью замены переменной в интеграле легко убедиться, что

$$
\Phi_{a,\sigma^2}(x)=\Phi_{0,1}\left(\frac{x-a}{\sigma}\right)
$$

[![](../截屏2022-11-10-17.18.58.png)](../截屏2022-11-10-17.18.58.png)

[successbox title="Лемма"]Функция распределения стандартного нормального распределения обладает следующими свойствами:

1. $\Phi_{0,1}(0)=\frac{1}{2}$
2. $\Phi_{0,1}(-x)=1-\Phi_{0,1}(x)$

[/successbox]

## Многомерные распределения

[h2title]Совместное распределение случайных величин[/h2title]

Пусть случайные величины $\xi_1, \xi_2, \cdots, \xi_n$ заданы на одном вероятностном пространстве $(\Omega, \sum, P)$. Введем в рассмотрение так называемый случайный вектор $\vec\xi = (\xi_1, \xi_2, \cdots, \xi_n)$.

[infobox title="标题内容"]Функцией распределения случайного вектора $\vec\xi$ называется функция

$$
F_{\vec\xi}=F_{\xi_1,\cdots,\xi_n}(x_1,\cdots,x_n)=P(\xi_1<x_1, \xi_2<x_2, \cdots, \xi_n<x_n)
$$

 На языке событий ясно, что $F_{\vec\xi}(x)$ – это вероятность события, что одновременнои $\xi_1<x_1$, и $\xi_2 < x_2$, и так далее, и $\xi_n < x_n$:

$$
P(\{\xi_1<x_1\}\cap\{\xi_2<x_2\}\cap\cdots\cap\{\xi_n<x_n\})
$$

[/infobox]

Конечно, введенное понятие обобщает понятие функции распределения случайной величины $\xi$. Сразу отметим очевидные (объясняемые аналогично одномерному случаю) свойства функции распределения случайного вектора. Для простоты, будем рассматривать вектор из двух компонент $(\xi_1, \xi_2)$, общий случай рассматривается аналогично.

[successbox title="Лемма"]Функция распределения случайного вектора $\vec\xi = (\xi_1, \xi_2)$ обладает следующими свойствами:

1. $F_{\vec\xi}\in[0,1]$.
2. $F_{\vec\xi}(x)$ не убывает по каждой координате.
3. При $i \in \{1,2\}$ справедливы равенства:
   $$
   \lim_{x_i\to-\infty}F_{\vec\xi}(x_1,x_2)=0, \lim_{x_1,x_2\to+\infty}F_{\vec\xi}(x_1,x_2)=1
   $$
4. $F_{\vec\xi}$ непрерывна слева по каждой координате.
5. По функции распределения случайного вектора восстанавливаются функции распределения компонент $\xi_i$, а именно при $i\in\{1,2\}$
   $$
   F_{\xi_i}(x)=\lim_{x_i\to+\infty}F_{\vec\xi}(x_1,x_2)
   $$

[/successbox]

Первая часть третьего свойства следует, грубо говоря, из того, что $\{\xi_i<-\infty\}=\emptyset$, а пересечение с таким событием дает тоже пустое множество, вероятность которого равна нулю. Вторая часть, как и в одномерном случае, следует из того, что каждая случайная величина принимает свои значения в промежутке $(-\infty,+\infty)$.

Из геометрических соображений легко видеть, что

$$
P(a_1 \le \xi_1 < b_1, a_2\le\xi_2<b_2)=F_{\vec\xi}(b_1,b_2)+F_{\vec\xi}(a_1,a_2)-F_{\vec\xi}(b_1,a_2)-F_{\vec\xi}(a_1,b_2)
$$

[h2title]Дискретное и абсолютно непрерывное многомерные распределения[/h2title]

Не нарушая общности, для простоты снова будем рассматривать век- тор, состоящий лишь из двух компонент $(\xi_1, \xi_2)$. Аналогично тому, как было сделано в первых лекциях, введем определение.

[infobox title=""]Говорят что случайный вектор $\vec\xi=(\xi_1,\xi_2)$ имеет дискретное распределение, если существует конечный или счетный набор чисел $\{a_i,b_j\}$, что

$$
\sum_{i,j} P(\xi_1=a_i, \xi_2=b_j)=1)
$$

[/infobox]

Как и ранее, по совместному распределению восстанавливаются распределения компонент, или маргинальные распределения по формулам

$$
\begin{aligned}&P(\xi_1=a_i)=\sum_{j}P(\xi_1=a_i,\xi_2=b_j)\\&P(\xi_2=b_j)=\sum_{i}P(\xi_1=a_i,\xi_2=b_j)\end{aligned}
$$

---

Теперь перейдем к многомерным абсолютно непрерывным распределениям.

[infobox title=""]Говорят что случайный вектор $\vec\xi$ имеет абсолютно непрерывное распределение, если существует такая неотрицательная функция $f_{\vec\xi}:\mathbb R^2 \to \mathbb R$, что

$$
F_{\vec\xi}(x_1,x_2)=\int_{-\infty}^{x_1}\int_{-\infty}^{x_2} f_{\vec\xi}(t_1,t_2)dt_1dt_2
$$

 Отдельно отметим, что в точках непрерывности плотности справедливо равенство

$$
\frac{\delta^2 F_{\vec\xi}(x_1,x_2)}{\delta x_1\delta x_2}=f_{\vec\xi}(x_1,x_2)
$$

[/infobox]

[infobox title="Теорема"]Пусть случайный вектор $\vec\xi = (\xi_1, \xi_2)$ имеет абсолютно непрерывное распределение с плотностью $f_{\vec\xi}(x_1,x_2)$. Тогда

$$
f_{\xi_1}(x)=\int_{-\infty}^{+\infty}f_{\vec\xi}(x,t)dt, f_{\xi_2}(x)=\int_{-\infty}^{+\infty}f_{\vec\xi}(t,x)dt
$$

 При $n>2$ для нахождения маргинального распределения компоненты $x_i$, плотность случайного вектора интегрируется по всем координатам, кроме $i$-ой.[/infobox]

---

[infobox title="Равномерное многомерное распределение"]Пусть
$D \subset \mathbb R^2$ – множество на плоскости, имеющее конечную площадь $\lambda(D)>0$. Говорят, что случайный вектор $\vec\xi=(\xi_1,\xi_2)$ имеет равномерное распределение в $D$, если его плотность имеет вид

$$
f_{\vec\xi}(x)=\left\{\begin{aligned}&\frac{1}{\lambda(D)},&x\in D\\&0,&x\notin D\end{aligned}\right.
$$

[/infobox]

[h2title]Независимость случайных величин[/h2title]

Как мы уже неоднократно отмечали, в теории вероятностей играют важную роль так называемые независимые события и независимые случайные величины. В случае произвольного вероятностного пространства, чтобы не вводить дополнительных определений, введем определение, отличающееся (по виду), от введенного нами в случае конечного пространства элементарных исходов.

[infobox title="Независимость случайных величин"]Случайные величины $\xi_1,\cdots,\xi_n$ называются независимыми (или независимыми в совокупности), если равенство

$$
F_{\xi_1,\cdots,\xi_n}(x_1,\cdots,x_n)=F_{\xi_1}(x_1)\cdot\cdots\cdot F_{\xi_n}(x_n)
$$

 справедливо для любых $x_1,\cdots,x_n$.

Иными словами, функция распределения случайного вектора в случае, когда его компоненты независимы, распадается в произведение функций распределений компонент.[/infobox]

[infobox title="Понятие попарной независимости"]Случайные величины $\xi_1,\cdots,\xi_n$ называются попарно независимыми, если независимы любые две из них.[/infobox]

попарная независимость событий не влечет независимость событий в совокупности.

[infobox title="Независимость дискретных случайных величин"]Случайные величины $\xi_1,\cdots,\xi_n$, имеющие дискретное совместное распределение, называются независимыми (или независимыми в совокупности), если равенство

$$
P(\xi_1=a_1,\cdots,\xi_n=a_n)=P(\xi_1=a_1)\cdot\cdots\cdot P(\xi_n=a_n)
$$

 справедливо для любых чисел $a_1,\cdots,a_n$.[/infobox]

В случае, когда случайные величины имеют абсолютно непрерывное распределение, их независимость может быть охарактеризована в терминах плотностей следующим образом.

[infobox title=""]Случайные величины $\xi_1,\cdots,\xi_n$, имеющие абсолютно непрерывное совместное распределение, называются независимыми (или независимыми в совокупности), если равенство

$$
f_{\xi_1,\cdots,\xi_n}(x_1,\cdots,x_n)=f_{\xi_1}(x_1)\cdot\cdots\cdot f_{\xi_n}(x_n)
$$

 справедливо для любых $x_1,\cdots,x_n$$.[/infobox]

# Числовые характеристики, сходимость

## Начальные сведения о функциях от случайных величин

[h2title]Монотонные преобразования[/h2title]

Ясно, что если $\xi$ имеет дискретное распределение, то и $g(\xi)$ имеет дискретное распределение, которое вычислить достаточно легко. Даже если какие-то значения случайной величины «склеиваются», то и соответствующие им вероятности «складываются». Например, имея случайную величину, заданную рядом распределения

| $\xi$ | $-1$          | $1$           | $2$            |
| ------- | --------------- | --------------- | ---------------- |
| $P$   | $\frac{1}{4}$ | $\frac{1}{3}$ | $\frac{5}{12}$ |

можно вычислить распределение случайной величины $\xi^2$. Так как при возведении в квадрат значения $-1$ и $1$ склеиваются, то ряд распределения для $\xi^2$ имеет вид

| $\xi$ | $1$                                    | $4$            |
| ------- | ---------------------------------------- | ---------------- |
| $P$   | $\frac{1}{4}+\frac{1}{3}=\frac{7}{12}$ | $\frac{5}{12}$ |

---

Пусть случайная величина $\xi$ имеет функцию распределения $F_\xi(x)$ и плотность распределения $f_\xi(x)$. Тогда при $a\neq 0$ случайная величина $\eta = a\xi + b$ имеет плотность распределения

$$
f_\eta (x)=\frac{1}{\lvert a \rvert}f_\xi\left(\frac{x-b}{a}\right)
$$

Пусть случайная величина $\xi$ имеет функцию распределения $F_\xi(x)$ и плотность распределения $f_\xi(x)$. Тогда при $a\neq 0$ случайная величина $\eta = a\xi + b$ имеет плотность распределения

$$
f_\eta(x)=\frac{1}{\lvert a \rvert}f_\xi\left(\frac{x-b}{a}\right)
$$

Пусть $a > 0$. Найдем функцию распределения случайной величины $\eta$.

$$
F_\eta(x) = P(\eta < x) = P(a\xi+b<x)=P(\xi < \frac{x-b}{a})=F_\xi(\frac{x-b}{a})
$$

Тогда

$$
F_\eta(x)=F_\xi(\frac{x-b}{a}=\int_{-\infty}^{\frac{x-b}{a}f_\xi(t)dt}
$$

В последнем интеграле сделаем замену $t=\frac{z-b}{a}$, тогда $dt=\frac{1}{a}dz$ и

$$
F_\eta(x)=\int_{-\infty}^x\frac{1}{a}\cdot f_\xi(\frac{z-b}{a}dz
$$

Рассуждения при $a<0$ практически аналогичны, проведите их самостоятельно. В итоге показано, что $\eta$ имеет абсолютно непрерывное распределение, а ее плотность равна

$$
f_\eta(x)=\frac{1}{\lvert a \rvert}f_\xi(\frac{x-b}{a})
$$

[warningbox title="Следствие"]

1. Пусть $\xi \sim N_{0,1}$, тогда $\eta = \sigma \xi + a \sim N_{a, \sigma^2}$.
2. Пусть $\xi \sim N_{a,\sigma^2}$, тогда $\eta = \frac{\xi - a}{\sigma} \sim N_{0,1}$.

[/warningbox]

Следующее следствие часто используется даже в том же программировании при моделировании случайности. Зачастую генератор случайных чисел выдает некоторое число $\xi$ в диапазоне $[0, 1]$ (моделирует равномерное распределение $U_{0,1}$). А как получить случайную точку на отрезке $[a, b]$?

[warningbox title="Следствие"]

1. Пусть $\xi \sim U_{0,1}$. Тогда $\eta = a + \xi(b-a) \sim U_{a,b}$.
2. Пусть $\xi \sim U_{a,b}$. Тогда $\eta = \frac{\xi - a}{b-a}\sim U_{0,1}$.

[/warningbox]

---

[infobox title="Теорема"]Пусть случайная величина $\xi$ имеет абсолютно непрерывное распределение с плотностью распределения $f_\xi$, а функция $g$ : $\mathbb R \to \mathbb R$ монотонна. Если $g^{-1}$ всюду непрерывно дифференцируема, то функция $\eta = g(\xi)$ имеет абсолютно непрерывное распределение с плотностью

$$
f_\eta(x)=f_\xi(g^{-1}(x))(g^{-1}(x))'
$$

[/infobox]

[h2title]Функции от нескольких случайных величин[/h2title]

[infobox title="Распределение суммы независимых с.в."]Пусть случайные величины $\xi_1$ и $\xi_2$ независимы и имеют абсолютно непрерывные распределения с плотностями $f_{\xi_1}(x)$ и $f_{\xi_2}(x)$. Тогда сумма $\xi_1+\xi_2$ имеет абсолютно непрерывное распределение, и ее плотность задается так называемой формулой свертки

$$
f_{\xi_1+\xi_2}(x)=\int_{-\infty}^{+\infty}f_{\xi_1}(t)f_{\xi_2}(x-t)dt
$$

 Итак, теорема устанавливает, что сумма независимых и абсолютно непре- рывных случайных величин имеет абсолютно непрерывное распределение, а также дает формулу для вычисления плотности этого распределения.[/infobox]

[warningbox title="标题内容"]

1. Пусть случайные величины $\xi_1$ и $\xi_2$ независимы и $\xi_1\sim N_{a_1,\sigma_1^2}, \xi_2\sim N_{a_2, \sigma_2^2}$, тогда $\xi_1 + \xi_2 \sim N_{a_1+a_2, \sigma_1^2+\sigma_2^2}$.Иными словами, сумма независимых нормально распределенных случайных величин с параметрами $a_1,\sigma_1^2$ и $a_2,\sigma_2^2$ тоже имеет нормальное распределение с параметрами $a_1+a_2, \sigma_1^2+\sigma_2^2$.
2. Пусть случайные величины $\xi_1$ и $\xi_2$ независимы и $\xi_1\sim \Pi_\lambda, \xi_2\sim \Pi_\mu$, тогда $\xi_1+\xi_2 \sim \Pi_{\lambda + \mu}$.
3. Пусть случайные величины $\xi_1$ и $\xi_2$ независимы и $\xi_1\sim Bin_{n,p}, \xi_2\sim Bin_{m,p}$, тогда $\xi_1 + \xi_2 \sim Bin_{n+m,p}$.

[/warningbox]

## Некоторые числовые характеристики случайных величин

[h2title]Медиана[/h2title]

[infobox title="Медиана"]Число $a \in \mathbb R$ называется медианой случайной величины $\xi$, если

$$
P(\xi \le a)\ge \frac{1}{2} \land P(\xi \ge a)\ge \frac{1}{2}
$$

[/infobox]

[h2title]Математическое ожидание[/h2title]

[infobox title="математического ожидания для дискретной"]Пусть случайная величина $\xi$ имеет дискретное распределение. Математическим ожиданием случайной величины $\xi$ называется число

$$
E\xi = \sum_{\omega \in \Omega}\xi(\omega)P(\omega) = \sum_{x\in\xi(\Omega)}xP(\xi = x)
$$

 при условии, что написанный ряд сходится абсолютно (то есть если существует $E\lvert\xi\rvert$). Иначе говорят, что математического ожидания не существует.[/infobox]

[infobox title="математического ожидания для абсолютно"]Пусть случайная величина $\xi$ имеет абсолютно непрерывное распределение с плотностью $f_\xi(x)$. Математическим ожиданием случайной величины $\xi$ называется число

$$
E\xi = \int_{-\infty}^{+\infty}xf_\xi(x)dx
$$

 при условии, что написанный интеграл сходится абсолютно (то есть если существует $E\lvert\xi\rvert$). Иначе говорят, что математического ожидания не существует.[/infobox]

[h2title]Свойства математического ожидания[/h2title]

[successbox title="Лемма"]

Во всех написанных свойствах предполагается, что математическое ожидание существует.

1. Пусть $g(x)$ – случайная величина, построенная по случайной величине $\xi$. Тогда если $\xi$ имеет дискретное распределение, то

   $$
   E(g(\xi))=\sum_{\omega\in\Omega}g(\xi(\omega))P(\omega)=\sum_ig(x_i)P(\xi=x_i)
   $$

   а если абсолютно непрерывное, то

   $$
   E(g(\xi))=\int_{-\infty}^{+\infty}g(x)f_\xi(x)dx
   $$
2. Пусть $\xi\ge 0$, тогда $E\xi\ge 0$. Иными словами, если случайная величина неотрицательна, то и ее среднее вероятностное неотрицательно.
3. $E(a\xi+b\eta)=aE\xi+bE\eta$ Иными словами, математическое ожидание линейно.
4. Пусть $\xi\ge\eta$ (это значит, что $\forall\omega\in\Omega$ выполняется $\xi(\omega)\ge\eta(\omega)$), тогда $E\xi\ge E\eta$. Иными словами, математическое ожидание монотонно.
5. $|E\xi|\le E|\xi|$
6. $(E|\xi\eta|)^2\le E\xi^2E\eta^2$
7. Если $\xi,\eta$ независимы, то $E(\xi\eta)=E\xi E\eta$.
8. Если $\xi = const$, то $E\xi = const$.

[/successbox]

[h2title]Вычисление математического ожидания у некоторых распределений[/h2title]

**Геометрическое распределение** Пусть случайная величина $\xi$ имеет геометрическое распределение, задаваемое таблицей

| $\xi$ | $1$ | $2$      | $\cdots$ | $n$            | $\cdots$ |
| ------- | ----- | ---------- | ---------- | ---------------- | ---------- |
| $P$   | $p$ | $(1-p)p$ | $\cdots$ | $(1-p)^{n-1}p$ | $\cdots$ |

$$
E\xi=\sum_{n=1}^\infty n(1-p)^{n-1}p = p\sum_{n=1}^\infty n(1-p)^{n-1}
$$

Для вычисления суммы последнего ряда, воспользуемся свойствами степенных рядов ведь, как легко заметить,

$$
\begin{aligned}\sum_{n=1}^\infty n(1-p)^{n-1}&=\sum_{n=1}^\infty (x^n)'\quad(x=1-p)\\&=(\sum_{n=1}^\infty x^n)'\quad(x=1-p)\\&=(\frac{x}{1-x})'\quad(x=1-p)\\&=\frac{1}{(1-x)^2}\quad(x=1-p)\\&=\frac{1}{p^2}\end{aligned}
$$

так как сумма ряда

$$
\sum_{n=1}^\infty x^n
$$

 при $|x|<1$, по сути, сумма бесконечно убывающей геометрической прогрессии, и равна $\frac{x}{1-x}$. Итого,

$$
E\xi=\frac{p}{p^2}=\frac{1}{p}
$$

Итак, как оказалось, математическое ожидание случайной величины, имеющей геометрическое распределение, обратно пропорционально вероятности успеха.

---

**Распределение Пуассона** Пусть $\xi\sim\Pi_\lambda, \lambda>0$, то есть

$$
P(\xi=k)\frac{\lambda^k}{k!}e^{-\lambda}, k\in\{0,1,2,3,\cdots,n,\cdots\}
$$

 Тогда

$$
E\xi = \sum_{k=0}^\infty k\frac{\lambda^k}{k!}e^{-\lambda} = e^{-\lambda}\sum_{k=1}^\infty \frac{\lambda^k}{(k-1)!}=\lambda e^{-\lambda}\sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!}=\lambda e^{-\lambda} e^{\lambda} = \lambda
$$

, так как

$$
\sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!}=e^{\lambda}
$$

---

**Равномерное распределение** Пусть $\xi\sim U_{a,b}$ то есть

$$
f_\xi(x)=\left\{\begin{aligned}&\frac{1}{b-a},&x\in[a,b]\\&0,&x\neq[a,b]\end{aligned}\right.
$$

 Тогда

$$
E\xi = \int_{-\infty}^{+\infty}xf_\xi(x)dx=\int_a^b\frac{x}{b-a}dx=\frac{b^2-a^2}{2(b-a)}=\frac{a+b}{2}
$$

 Итак, у равномерно распределенной на отрезке случайной величины среднее значение находится в середине отрезка, на котором плотность отлична от нуля. Неудивительно, не так ли?

---

**Показательное распределение** Пусть случайная величина $\xi$ имеет показательное распределение $\xi \sim Exp_\lambda, \lambda > 0$, то есть ее плотность задается соотношением

$$
f_\xi(x)=\left\{\begin{aligned}&0,&x<0\\&\lambda e^{-\lambda x},&x\ge 0\end{aligned}\right.
$$

 Тогда

$$
E\xi = \int_{-\infty}^{+\infty}xf_\xi(x)dx=\lambda\int_0^{+\infty}xe^{-\lambda x}dx=\lambda (-\frac{x}{\lambda}e^{-\lambda x}|_0^{+\infty}+\frac{1}{\lambda}\int_0^{+\infty}e^{-\lambda x}dx)=\frac{1}{\lambda}
$$

---

**Стандартное нормальное распределение** Пусть $\xi\sim N_{0,1}$, то есть

$$
f_\xi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$

 Тогда

$$
E\xi = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}xe^{-\frac{x^2}{2}}dx=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{x^2}{2}}d(\frac{x^2}{2}) = -\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}|_{-\infty}^{+\infty}=0
$$

---

**Нормальное распределение** Пусть $\xi\sim N_{a,\sigma^2}$, то есть

$$
f_\xi(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-a)^2}{2\sigma^2}}
$$

 Как мы знаем, случайная величина $\xi$ может быть представлена, как $\xi = \sigma\eta + a$, где $\eta \sim N_{0,1}$. Согласно свойствам математического ожидания,

$$
E\xi = E(\sigma\eta+a)=\sigma E_\eta+a=a
$$

 Значит, математическое ожидание случайной величины $\xi$ равно $a$.

---

Математическое ожидание определено не всегда.

1. **Распределение Коши**

   $$
   \begin{aligned}&f_\xi(x)=\frac{1}{\pi}\cdot\frac{1}{1+x^2}\\&E\xi=\frac{1}{\pi}\int_{-\infty}^{+\infty}\frac{x}{1+x^2}dx=\frac{1}{2\pi}\ln(1+x^2)|_{-\infty}^{+\infty}\end{aligned}
   $$

   .
2. $$
   \begin{aligned}&P(\xi=k)=\frac{1}{k(k+1)},k\in\{1,2,\cdots\}\\&E\xi=\sum_{k=1}^{+\infty}\frac{k}{k(k+1)}=\sum_{k=1}^{+\infty}\frac{1}{k+1}\end{aligned}
   $$

[h2title]Дисперсия и моменты старших порядков[/h2title]

Мы уже знакомы с понятием дисперсии из простейшего случая. Посмотрим, как определяются моменты (и центральные моменты) старших поряд- ков. Введем следующие определения в предположении, что существует $E|\xi|^k$.

[infobox title="标题内容"]

1. Число $E\xi^k$ называется моментом $k$-ого порядка, или $k$-ым моментом случайной величины $\xi$.
2. Число $E|\xi|^k$ называется абсолютным моментом $k$-ого порядка, или абсолютным $k$-ым моментом случайной величины $\xi$.
3. Число $E(\xi -E\xi)^k$ называется центральным моментом $k$-ого порядка, или центральным $k$-ым моментом случайной величины $\xi$.
4. Число $E|\xi -E\xi|^k$ называется абсолютным централь- ным моментом $k$-ого порядка, или абсолютным центральным $k$-ым момен- том случайной величины $\xi$.

Пусть существует момент $k$-ого порядка случайной величины $\xi$. Тогда при $0<r<k$ существует и момент $r$-ого порядка.

[/infobox]

[infobox title="дисперсия"]Центральный момент второго порядка называется дисперсией случайной величины $\xi$. Как и раньше,

$$
D\xi = E(\xi-E\xi)^2
$$

[/infobox]

[infobox title="среднеквадратическое отклонение"]Пусть существует дисперсия $D\xi$ случайной величины $\xi$. Тогда величина

$$
\sigma_\xi = \sqrt{D\xi}
$$

 называется среднеквадратическим отклонением.[/infobox]

[successbox title="Лемма"]Во всех свойствах предполагается, что вторые моменты случайных величин существуют.

1. $D\xi \ge 0$.
2. $D\xi = E\xi^2 - (E\xi)^2$
3. $D(\xi + a)=D\xi$
4. $D(c\xi)=c^2D\xi$
5. Если $\xi$ и $\eta$ – независимые случайные величины, то $D(\xi+\eta)=D\xi+D\eta$.
6. Для произвольных случайных величин $\xi$ и $\eta$ с конечными дисперсиями справедливо равенство
   $$
   D(\xi+\eta)=D\xi+D\eta+2(E(\xi\eta)-E\xi E\eta)
   $$

[/successbox]

[h2title]Вычисление дисперсий некоторых распределений[/h2title]

**Геометрическое распределение** Пусть случайная величина $\xi$ имеет геометрическое распределение, задаваемое таблицей

| $\xi$ | $1$ | $2$      | $\cdots$ | $n$            | $\cdots$ |
| ------- | ----- | ---------- | ---------- | ---------------- | ---------- |
| $P$   | $p$ | $(1-p)p$ | $\cdots$ | $(1-p)^{n-1}p$ | $\cdots$ |

Напомним, что $E\xi=\frac{1}{p}$. Вычислим дисперсию. Для вычисления величины $E\xi^2$ бывает удобно вычислить $E(\xi(\xi-1))$ и воспользоваться тождеством

$$
E\xi^2=E(\xi(\xi-1))+E\xi
$$

Итак, снова используя свойства степенных рядов,

$$
\begin{aligned}E(\xi(\xi-1))&=\sum_{k=1}^\infty k(k-1)(1-p)^{k-1}p\\&=p(1-p)\sum_{k=0}^\infty k(k-1)(1-p)^{k-2}\\&=p(1-p)\sum_{k=0}^\infty (x^k)''\qquad(x=1-p)\\&=p(1-p)(\sum_{k=0}^\infty x^k)''\qquad(x=1-p)\\&=p(1-p)(\frac{1}{1-x})''\qquad(x=1-p)\\&=\frac{2(1-p)}{p^2}\end{aligned}
$$

Значит,

$$
E\xi^2=\frac{2(1-p)}{p^2}+\frac{1}{p}=\frac{2-p}{p^2}
$$

Тогда

$$
D\xi = E\xi^2-(E\xi)^2=\frac{2-p}{p^2}-\frac{1}{p^2}=\frac{1-p}{p^2}
$$

можно утверждать, что в среднем значения случайной величины $\xi$ находятся в интервале

$$
(E\xi-\sigma_\xi,E\xi+\sigma_\xi)
$$

---

**Распределение Пуассона** Пусть $\xi \sim \Pi_\lambda, \lambda > 0$, то есть

$$
P(\xi=k)=\frac{\lambda^k}{k!}e^{-\lambda},k\in\{0,1,2,3,\cdots,n,\cdots\}
$$

Как мы знаем, $E\xi = \lambda$. Вычислим $E\xi^2$ аналогичным образом, сначала вычислив

$$
\begin{aligned}E(\xi(\xi-1))&=\sum_{k=0}^\infty k(k-1)\frac{\lambda^k}{k!}e^{-\lambda}\\&=\lambda^2e^{-\lambda}\sum_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!}\\&=\lambda^2e^{-\lambda}e^{\lambda}\\&=\lambda^2\end{aligned}
$$

Значит,

$$
D\xi=E\xi^2-(E\xi)^2=E(\xi(\xi-1))+E\xi-(E\xi)^2=\lambda^2+\lambda-\lambda^2=\lambda
$$

Итак, у распределения Пуассона совпадают математическое ожидание и дисперсия.

---

**Равномерное распределение** Пусть $\xi\sim U_{a,b}$, то есть

$$
f_\xi(x)=\left\{\begin{aligned}&\frac{1}{b-a},&x\in[a,b]\\&0,&x\neq[a,b]\end{aligned}\right.
$$

мы знаем, что $E\xi = \frac{a+b}{2}$. Вычислим $E\xi^2$, тогда

$$
E\xi^2=\int_{-\infty}^{+\infty}x^2f_\xi(x)dx=\int_a^b\frac{x^2}{b-a}dx=\frac{b^2+ab+a^2}{3}
$$

Отсюда следует, что

$$
D\xi = E\xi^2-(E\xi)^2=\frac{b^2+ab+a^2}{3}-\frac{(a+b)^2}{4}=\frac{(b-a)^2}{12}
$$

---

**Показательное распределение** Пусть случайная величина $\xi$ имеет показательное распределение $\xi\sim Exp_\lambda, \lambda > 0$, то есть ее плотность задается соотношением

$$
f_\xi(x)=\left\{\begin{aligned}&0,&x<0\\&\lambda e^{-\lambda x},&x\ge 0\end{aligned}\right.
$$

Мы знаем, что $E\xi = \frac{1}{\lambda}$ . Значит,

$$
\begin{aligned}E\xi^2&=\int_{-\infty}^{+\infty}x^2f_\xi(x)dx \\&= \lambda\int_0^{+\infty}x^2e^{-\lambda x}dx\\&=-x^2e^{-\lambda x}|_0^{+\infty}+2\int_0^{+\infty}xe^{-\lambda x}dx\\&=\frac{2}{\lambda^2}\end{aligned}
$$

так как последний интеграл равен $\frac{E\xi}{\lambda}=\frac{1}{\lambda^2}$. Тогда

$$
D\xi=\frac{2}{\lambda^2}-\frac{1}{\lambda^2}=\frac{1}{\lambda^2}
$$

---

**Стандартное нормальное распределение** Пусть $\xi\sim N_{0,1}$, то есть

$$
f_\xi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$

Мы уже знаем, что $E\xi=0$. Тогда

$$
\begin{aligned}E\xi^2&=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}x^2e^{-\frac{x^2}{2}}dx\\&=-\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}xd(e^{-\frac{x^2}{2}})\\&=-\frac{x}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}|_{-\infty}^{+\infty}+\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{+\infty}e^{-\frac{x^2}{2}}dx\\&=1\end{aligned}
$$

Значит,

$$
D\xi = E\xi^2-(E\xi)^2=1
$$

---

**Нормальное распределение** Пусть $\xi\sim N_{a,\sigma^2}$, то есть

$$
f_\xi(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-a)^2}{2\sigma^2}}
$$

.

Как мы знаем, случайная величина $\xi$ может быть представлена, как $\xi = \sigma\eta+a$, где $\eta\sim N_{0,1}$. Согласно свойствам дисперсии,

$$
D\xi = D(\sigma\eta+a)=\sigma^2D\eta=\sigma^2
$$

Значит, второй параметр нормального распределения – это дисперсия.

[h2title]Ковариация и корреляция[/h2title]

[infobox title="Ковариация"]Величина $E(\xi\eta)-E\xi E\eta$ называется ковариацией случайных величин $\xi$ и $\eta$ и обозначается $cov(\xi, \eta)$.

Прямые выкладки показывают, что ковариация может быть определена и следующим способом:

$$
cov(\xi,\eta) = E((\xi-E\xi)(\eta-E\eta))
$$

[/infobox]

[successbox title="Лемма"]

Ковариация обладает следующими свойствами.

1. $cov(\xi, \eta)=cov(\eta, \xi)$;
2. $cov(a\xi, b\eta)=abcov(\xi, \eta)$;
3. $cov(\xi+c, \eta+d)=cov(\xi, \eta)$;
4. $cov(\xi, \xi) = D\xi$.

[/successbox]

Абсолютно аналогично мотивируется введение корреляции – она оказывается безразмерной, в отличие от ковариации.

[infobox title="Коэффициент корреляции"]Коэффициентом корреляции двух величин $\xi$ и $\eta$ с отличными от нуля дисперсиями, называется величина

$$
\rho(\xi, \eta) = \frac{cov(\xi,\eta)}{\sqrt{D\xi}\sqrt{D\eta}}=\frac{cov(\xi,\eta)}{\sigma_\xi\sigma_\eta}
$$

[/infobox]

Как и раньше, коэффициент корреляции показывает степень линейной зависимости. Чем ближе его значение к единице, тем «более линейна» зависимость.

[successbox title="Лемма"]Коэффициент корреляции обладает следующими свойствами:

1. его абсолютное значение не превосходит единицы, то есть $\lvert \rho(\xi, \eta)\rvert \le 1$;
2. Если $\xi, \eta$ – независимы, то $\rho(\xi, \eta) = 0$;
3. $\lvert \rho(\xi, \eta)\rvert \le 1$ тогда и только тогда, когда $\xi = a\eta+b$, причем $a\cdot \rho(\xi, \eta) > 0$.

[/successbox]

## Сходимость последовательностей случайных величин

Все предельные теоремы основаны, конечно же, на предельном переходе. В то же время, мы теперь работаем со случайными величинами – функциями на пространстве элементарных исходов. И что понимать под сходимостью функций? Давайте разбираться.

[h2title]Различные типы сходимостей и их связи[/h2title]

[infobox title="Сходимость по вероятности"]

Говорят, что последовательность случайных величин $\xi_n$, заданных на вероятностном пространстве $(\Omega, \sum, P)$, сходится к случайной величине $\xi$, заданной на том же вероятностном пространстве, по вероятности, если

$$
\forall \varepsilon > 0\quad \lim_{n\to+\infty}P(|\xi_n-\xi|>\varepsilon)=0
$$

Иными словами, вероятность события $\{\omega\in\Omega:|\xi_n(\omega)-\xi(\omega|>\varepsilon\}$ стремится к нулю с ростом 𝑛 для каждого наперед заданного $\varepsilon > 0$. Сходимость по вероятности часто обозначают следующим образом

$$
\xi_n \to \xi\qquad (n\to+\infty)
$$

[/infobox]

[successbox title="Лемма"]

Пусть $\xi_n \to \xi, \eta_n\to\eta$, тогда

1. $\xi_n+\eta_n\to\xi+\eta$
2. $\xi_n\eta_n \to \xi\eta$
3. Пусть функция $g(x)$ непрерывна, тогда $g(\xi_n)\to g(\xi)$

[/successbox]

---

Из курса анализа нам знакомо понятие поточечной сходимости, а именно: $\xi_n \to \xi$ поточечно на множестве $\Omega$, если $\forall \omega \in \Omega \Rightarrow \xi_n(\omega)\to\xi(\omega)$

Поточечная сходимость означает сходимость соответствующей числовой последовательности в каждой точке множества $\Omega$. В теории вероятностей логичнее рассматривать ослабленную поточечную сходимость.

[infobox title="Сходимость почти наверное"]Говорят, что последовательность случайных величин $\xi_n$, заданных на вероятностном пространстве $(\Omega, \sum, P)$, сходится к случайной величине $\xi$, заданной на том же вероятностном пространстве, почти наверное (или с вероятностью 1), если

$$
P\left(\omega\in\Omega:\lim_{n\to\infty}\xi_n(\omega)=\xi(\omega)\right)=1
$$

[/infobox]

[infobox title="Сходимость по распределению"]Говорят, что последовательность случайных величин $\xi_n$, заданных на вероятностном пространстве $(\Omega,\sum,P)$, сходится к случайной величине $\xi$, заданной на том же вероятностном пространстве, по распределению (слабо), если

$$
\lim_{n\to\infty}F_{\xi_n}(x)=F_\xi(x)
$$

 во всех точках $x$, в которых предельная функция $F_\xi(x)$ непрерывна.[/infobox]

[h2title]Неравенства Маркова и Чебышёва[/h2title]

Аналогично тому, что было сделано в простейшем случае, сформулируем неравенства Маркова и Чебышева.

[infobox title="Неравенство Маркова"]Пусть случайная величина $\xi\ge 0$ и существует $E\xi$. Тогда для каждого $a>0$

$$
P(\xi\ge a)\le\frac{E\xi}{a}
$$

[/infobox]

Из неравенства Маркова вытекает хорошо знакомое нам неравенство Чебышёва.

[infobox title="Неравенство Чебышёва"]Пусть существует момент второго порядка $E\xi^2$. Тогда для каждого $a>0$

$$
P(|\xi-E\xi|\ge a)\le\frac{D\xi}{a^2}
$$

[/infobox]

[h2title]Закон больших чисел[/h2title]

$$
S_n = \xi_1 + \xi_2 + \cdots + \xi_n
$$

[infobox title="ЗБЧ в форме Чебышёва"]Пусть $\xi_1, \cdots, \xi_n,\cdots$ – последовательность попарно независимых и одинаково распределенных случайных величин, причем существует второй момент $E\xi_1^2$. Тогда

$$
\forall \varepsilon > 0\qquad \lim_{n\to\infty}P\left(\left|\frac{S_n}{n}-E\xi_1\right|>\varepsilon\right)=0
$$

[/infobox]

[infobox title="ЗБЧ в форме Хинчина"]Пусть $\xi_1, \cdots, \xi_n,\cdots$ – последова- тельность независимых в совокупности и одинаково распределенных случайных величин, причем существует первый момент $E\xi_1$. Тогда

$$
\forall \varepsilon > 0\qquad \lim_{n\to\infty}P\left(\left|\frac{S_n}{n}-E\xi_1\right|>\varepsilon\right)=0
$$

[/infobox]

Следующую формулировку закона больших чисел часто называют усиленным законом больших чисел.

[infobox title="ЗБЧ в форме Колмогорова"]Пусть $\xi_1, \cdots, \xi_n,\cdots$ – последовательность независимых в совокупности и одинаково распределенных случайных величин, причем существует первый момент $E\xi_1$. Тогда

$$
P\left(\omega\in\Omega:\lim_{n\to\infty}\frac{S_n}{n}=E\xi_1\right)=1
$$

[/infobox]

Тем самым, ЗБЧ в форме Колмогорова устанавливает, что среднее арифметическое сходится к математическому ожиданию не только по вероятности, но и почти наверное. Как мы знаем, сходимость почти наверное сильнее, чем сходимость по вероятности. Именно поэтому данная теорема часто носит название «усиленного» закона больших чисел.

[h2title]Центральная предельная теорема[/h2title]

Как мы знаем, среднее арифметическое попарно независимых случайных величин $\xi_1,\cdots,\xi_n$ с конечным вторым моментом сходится по вероятности к $E\xi_1$. Иными словами,

$$
\frac{S_n}{n}-E\xi_1=\frac{S_n-nE\xi_1}{n}\to 0\quad(n\to\infty)
$$

Можно ли найти такую функцию $f(n)$, что при умножении на эту функцию сходимость будет не к нулю, а к какому-то числу, отличному от нуля, то есть

$$
f(n)\cdot\frac{S_n-nE\xi_1}{n}\to a \neq 0
$$

Найдя такую функцию $f(n)$, мы сможем говорить о так называемой скорости сходимости к нулю. Центральная предельная теорема говорит о том, что в качестве $f(n)$ можно взять $f(n)=\sqrt{n}$.

[infobox title="ЦПТ в форме Ляпунова"]Пусть $\xi_1,\cdots,\xi_n,\cdots$ – независимые в совокупности, одинаково распределенные случайные величины, у которых существует второй момент, а дисперсия отлична от нуля. Тогда имеет место слабая сходимость

$$
\frac{S_n-nE\xi_1}{\sqrt{nD\xi_1}}\to N_{0,1}\quad(n\to+\infty)
$$

[/infobox]

Итак, согласно центральной предельной теореме, «центрированная» (так как вычитается математическое ожидание $S_n$) и «нормированная» (так как делится на дисперсию $S_n$) случайная величина $S_n$ сходится слабо к стандартному нормальному распределению.

# Установочная лекция по статистике

## Введение в статистику

[h2title]Самое-самое введение и мотивировка[/h2title]

[infobox title="точка локального максимума"]Модой случайной величины $\xi$, имеющей абсолютно непрерывное распределение с плотностью $f_\xi$, называется точка локального максимума $f_xi$.

Если же случайная величина $\xi$ имеет дискретное распределение, заданное таблицей

| $\xi$ | $a_1$ | $a_2$ | $\cdots$ | $a_n$ | $\cdots$ |
| ------- | ------- | ------- | ---------- | ------- | ---------- |
| $P$   | $p_1$ | $p_2$ | $\cdots$ | $p_n$ | $\cdots$ |

то модой случайной величины $\xi$ называется произвольное значение $a_i$ такое, что

$$
p_{i-1}\le p_i, p_{i+1}\le p_i
$$

 если хотя бы одна из соседствующих вероятностей определена.

[![](../截屏2022-11-19-13.32.09.png)](../截屏2022-11-19-13.32.09.png)

[/infobox]

Легко понять (кроме как, возможно, для биномиального распределения $Bin_{n,p}$), что почти что все распределения, которые мы рассматривали: вырожденное, Бернулли, биномиальное, Пуассона, показательное, нормальное (короче все, кроме равномерного и левого хвоста показательного) – унимодальные.

[h2title]Немного о выборке[/h2title]

[infobox title="标题内容"]Пусть $\xi$ – рассматриваемая нами случайная величина. Выборкой (после эксперимента)

$$
X=(x_1,x_2,\cdots,x_n)\in\mathbb R^n
$$

 называется 𝑛 независимых реализаций случайной величины $\xi$. Последнюю часто называют генеральной совокупностью.[/infobox]

[infobox title="общее определение выборки"]Пусть $\xi$ – рассматриваемая нами случайная величина. Выборкой $X=(X_1,X_2,\cdots,X_n)$ называется 𝑛 независимых случайных величин, имеющих распределение такое же, как и $\xi$.[/infobox]

## Оценки характеристик распределения

[h2title]Эмпирическое распределение[/h2title]

[infobox title="ЗБЧ для эмпирического распределения"]Для каждого множества $A\in\mathbb R$ имеет место сходимость почти наверное:

$$
\frac{|\{X_i:X_i\in A\}|}{n}\rightarrow P(\xi\in A)\quad(n\to+\infty)
$$

[/infobox]

[h2title]Немного о качестве оценок[/h2title]

Можно измерить то, насколько ошибка хорошая, используя среднеквадратическую ошибку:

$$
MSE=E(\hat \theta - \theta)^2
$$

Распишем последнее выражение подробнее, раскрыв скобки и учитывая, что
$\theta\in\mathbb R$:

$$
\begin{aligned}E(\hat\theta-\theta)^2&=E(\hat\theta^2-2\hat\theta\theta+\theta^2)\\&=E\hat\theta^2-2\theta E\hat\theta + \theta^2\\&=E\hat\theta^2-(E\hat\theta)^2+(E\hat\theta)^2-2\theta E\hat\theta + \theta^2\\&=D\hat\theta + (E\hat\theta-\theta)^2\end{aligned}
$$

откуда

$$
MSE=D\hat\theta+(E\hat\theta-\theta)^2
$$

Ясно, что чтобы оценка была разумной, хотелось бы, чтобы ошибка $MSE$ стремилась к нулю при объеме выборки 𝑛, стремящемся к бесконечности.

[successbox title="标题内容"]

Оценка $\hat\theta$ называется несмещенной, если

$$
E\hat\theta=\theta
$$

.

Оценка $\hat\theta$ называется асимптотически несмещенной, если

$$
\lim_{n\to+\infty} E\hat\theta=\theta
$$

.

Оценка $\hat\theta$ называется состоятельной в смысле среднеквадратического, если $MSE$ стремится к нулю с ростом $n$.

[/successbox]

[h2title]Параметрические модели[/h2title]

[successbox title="Лемма"]Выборочное среднее имеет нормальное распределение

$$
N_{a,\sigma^2/n}
$$

.[/successbox]

## Интервальное оценивание

[h2title]Немного об интервальном оценивании[/h2title]

[infobox title="标题内容"]Доверительный интервал, построенный по выборке $X=(X_1,X_2,\cdots,X_n)$ уровня доверия $0.95$ – это интервал с концами $\theta^\pm(X_1,X_2,\cdots,X_n)$, для которого

$$
P(\theta^-<\theta<\theta^+)\ge 0.95
$$

[/infobox]

## Проверка гипотез

# Выборочные характеристики

## Введение

[h2title]Основные понятия и задачи математической статистики[/h2title]

[info]Выборкой $X=(X_1,\cdots,X_n)$ объема 𝑛 называется набор из $n$ независимых одинаково распределенных случайных величин $X_1,\cdots,X_n$, имеющих распределение такое же, как и у случайной величины $\xi$.

Рассматриваемая случайная величина $\xi$ часто называется генеральной совокупностью.[/info]

## Выборочные характеристики

[h2title]Выборочное распределение[/h2title]

Таблица распределения случайной величины $\xi^*$ имеет очень простой вид

| $\xi^*$ | $X_1$       | $X_2$       | $\cdots$ | $X_n$       |
| --------- | ------------- | ------------- | ---------- | ------------- |
| $P$     | $\frac 1 n$ | $\frac 1 n$ | $\cdots$ | $\frac 1 n$ |

Математическое ожидание величины $\xi^*$ равно

$$
\widetilde E\xi^* = \overline X = \frac{X_1+X_2+\cdots+X_n}{n}
$$

дисперсия $\widetilde D\xi^*$ же, как обычно, равна $\widetilde E(\xi^*-\widetilde E\xi^*)^2$ или

$$
\widetilde D\xi^*=S^2=\frac 1 n \sum_{i=1}^n (X_i - \widetilde E\xi^*)^2=\frac 1 n \sum_{i=1}^n (X_i - \overline X)^2
$$

момент $k$-ого порядка равен

$$
\widetilde E(\xi^*-\widetilde E\xi^*)^k = \hat m_k = \frac 1 n \sum_{i=1}^n (X_i - \widetilde E\xi^*)^k = \frac 1 n \sum_{i=1}^n(X_i - \overline X)^k
$$

и вообще, математическое ожидание функции $g$ от случайной величины $\xi^*$ равно

$$
\widetilde Eg(\xi^*) = \overline{g(X)} = \frac 1 n \sum_{i=1}^n g(X_i)
$$

Кстати, дисперсия может быть вычислена и как

$$
D\xi^* = S^2 = \overline{X^2}-(\overline X)^2
$$

[h2title]Эмпирическая функция распределения[/h2title]

[infobox title="понятие вариационного ряда"]Пусть имеется выборка $X=(X_1,\cdots,X_n)$. Если элементы выборки упорядочить по возрастанию, то новый набор случайных величин, удовлетворяющий неравенствам

$$
X_{(1)}\le X_{(2)}\le \cdots \le X_{(n)}
$$

, называется вариационным рядом.[/infobox]

[infobox title="Основные свойства ЭФР"]Пусть $X_1,\cdots,X_n$ – выборка из генеральной совокупности $\xi$ с функцией распределения $F_\xi$. Тогда эмпирическая функция распределения $F_n^*(t)$, построенная по этой выборке, удовлетворяет следующим свойствам:

1. Эмпирическая функция распределения является состоятельной оценкой $F_\xi$, то есть
   $$
   F_n^*(t)\to F_\xi(t), \forall t \in \mathbb R, n\to +\infty
   $$
2. Эмпирическая функция распределения является несмещенной оценкой $F_\xi$, то есть
   $$
   EF_n^*(t)=F_\xi(t)
   $$
3. Дисперсия эмпирической функции распределения равна
   $$
   DF_n^*(t)=\frac{F_\xi(t)(1-F_\xi(t))}{n}
   $$
4. Эмпирическая функция распределения при $F_\xi(t)\neq 0, F_\xi(t)\neq 1$ является асимптотически нормальной оценкой $F_\xi$, то есть
   $$
   Y_n = \sqrt n \frac{F_n^*(t)-F_\xi(t)}{\sqrt{DF_n^*}}\to Y\sim N_{0,1}\quad n\to+\infty
   $$

[/infobox]

[infobox title="Гливенко-Кантелли"] Пусть $X_1,\cdots,X_n$ – выборка из генеральной совокупности $\xi$ с функцией распределения $F_\xi$. Тогда эмпирическая функция распределения $F_n^*(t)$, построенная по этой выборке, сходится к истинной «почти равномерно», то есть

$$
sup_{t\in\mathbb R}|F_n^*(t)-F_\xi(t)|\to 0\quad(n\to+\infty)
$$

[/infobox]

[infobox title="Колмогорова"]Пусть $X_1,\cdots,X_n$ – выборка из генеральной совокупности $\xi$ с непрерывной функцией распределения $F_\xi$. Тогда для эмпирической функция распределения $F_n^*(t)$ выполняется

$$
Y_n = \sqrt n \cdot sup_{t\in\mathbb R}|F_n^*(t)-F_\xi(t)|\to Y\quad(n\to+\infty)
$$

 где случайная величина $Y$ имеет распределение Колмогорова с функцией распределения

$$
F_Y(t)=\left\{\begin{aligned}&\sum_{i=-\infty}^{+\infty}(-1)^ie^{-2i^2t^2},&t\ge 0\\&0,&t<0\end{aligned}\right.
$$

[/infobox]

[h2title]Гистограмма[/h2title]

[successbox title="Лемма"]Пусть плотность распределения $f_\xi$ генеральной совокупности $\xi$ – непрерывная функция, $k(n)$ – количество интервалов группировки. Если $k(n)\to+\infty(n\to+\infty)$ так, что

$$
\frac{k(n)}{n}\to 0(n\to+\infty)
$$

 и длина каждого из интервалов группировки стремится к нулю, то гистограмма в каждой точке сходится к истинной плотности $f_\xi$ по вероятности.[/successbox]

Часто число интервалов группировки берут пропорционально $\sqrt[3]{n}$.

[infobox title="Основное свойство гистограммы"]Предположим, что случайная величина $\xi$ имеет абсолютно непрерывное распределение с плотностью $f_\xi$. Для любого $j\in\{1,2,\cdots,k\}$ при $n\to\infty$ имеет место сходимость по вероятности

$$
\frac{\nu_j}{n}\to\int_{A_j}f_\xi(x)dx\quad(n\to+\infty)
$$

[/infobox]

[h2title]Выборочные моменты[/h2title]

[infobox title="标题内容"]Выборочным средним называется случайная величина

$$
\overline X = \frac{X_1+X_2+\cdots+X_n}{n}=\frac{1}{n}\sum_{i=1}^n X_i
$$

[/infobox]

Ясно, что выборочное среднее логично считать оценкой для математического ожидания истинного распределения, так как выборочное распределение при больших объемах выборки сходится по вероятности к истинному.

[infobox title="Свойства выборочного среднего"]Выборочное среднее обладает следующими свойствами:

1. Если $E|X_1|<+\infty$, то $E\overline X = EX_1$. Итак, выборочное среднее является несмещенной оценкой математического ожидания.
2. Если $E|X_1|<+\infty$, то $\overline X \to EX_1\quad(n\to+\infty)$, то есть выборочное среднее является состоятельной оценкой математического ожидания.
3. Если $DX_1\in(0,+\infty)$, то

   $$
   Y_N=\sqrt n \frac{\overline X - EX_1}{\sqrt{DX_1}}\to Y\sim N_{0,1}\quad(n\to\infty)
   $$

   что означает, что выборочное среднее является асимптотически нормальной оценкой математического ожидания.

[/infobox]

[infobox title="Свойства выборочных моментов $k$-ого порядка"]Выборочным моментом $k$-ого порядка называется случайная величина

$$
\overline{X^k} = \frac{X_1^k+X_2^k+\cdots+X_n^k}{n}=\frac{1}{n}\sum_{i=1}^n X_i^k
$$

Выборочные моменты $k$-ого порядка являются несмещенными, состоятельными и асимптотически нормальными оценками для истинного $k$-ого момента, а именно:

1. Если $E|X_1|^k<+\infty$, то $E\overline{X^k}=EX_1^k$.
2. Если $E|X_1|^k<+\infty$, то $\overline{X^k}=EX_1^k\quad(n\to\infty)$
3. Если $DX_1^k\in(0,+\infty)$, то
   $$
   Y_n = \sqrt n \frac{\overline{X^k}-EX_1^k}{\sqrt{DX_1^k}}\to Y\sim N_{0,1}\quad(n\to\infty)
   $$

[/infobox]

[infobox title="выборочная дисперсия"]Выборочной дисперсией называется случайная величина

$$
S^2 = \frac 1 n \sum_{i=1}^n (X_i-\overline X)^2
$$

Для выборочной дисперсии справедливы соотношения

$$
S^2 = \overline{X^2}-\overline X^2
$$

[/infobox]

[warningbox title="Теорема"]Выборочная дисперсия обладает следующими свойствами:

1. Если $DX_1<+\infty$, то $S^2$ – смещенная оценка дисперсии, а именно
   $$
   ES^2=\frac{n-1}{n}DX_1
   $$
2. Если $DX_1<+\infty$, то $S^2$ – состоятельная оценка дисперсии, а именно
   $$
   S^2 \to DX_1\quad(n\to\infty)
   $$
3. Если $0<D(X_1-EX_1)^2<+\infty$, то $S^2$ – асимптотически нормальная оценка дисперсии, а именно
   $$
   Y_n = \sqrt n \frac{S^2-DX_1}{\sqrt{D(X_1-EX_1)^2}}\to Y\sim N_{0,1}\quad(n\to\infty)
   $$

[/warningbox]

[infobox title="标题内容"]Несмещенной выборочной дисперсией называется случайная величина

$$
S_0^2 = \frac{n}{n-1}S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline X)^2
$$

[/infobox]

[warningbox title="Теорема"]Несмещенная выборочная дисперсия обладает следующими свойствами:

1. Если $DX_1<+\infty$, то $S_0^2$ – несмещенная оценка дисперсии, а именно
   $$
   ES_0^2=DX_1
   $$
2. Если $DX_1<+\infty$, то $S_0^2$ – состоятельная оценка дисперсии, а именно
   $$
   S_0^2\to DX_1\quad(n\to\infty)
   $$
3. Если $0<D(X_1-EX_1)^2<+\infty$, то $S_0^2$ – асимптотически нормальная оценка дисперсии, а именно
   $$
   Y_n = \sqrt{n}\frac{S_0^2-DX_1}{\sqrt{D(X_1-EX_1)^2}}\to Y\sim N_{0,1}\quad(n\to\infty)
   $$

[/warningbox]

[h2title]Выборочные квантили[/h2title]

[infobox title="标题内容"]Пусть фиксировано число $\alpha \in (0,1)$. Квантилью уровня $\alpha$ называется такое число $x_\alpha$, что

$$
P(\xi\le x_\alpha)\ge\alpha,P(\xi\ge x_\alpha)\ge 1-\alpha
$$

[/infobox]

[infobox title="标题内容"]Пусть $X_1,X_2,\cdots,X_n$ – выборка из генеральной совокупности $\xi$. Число

$$
\hat x_\alpha=\left\{\begin{aligned}&X_{([n\alpha]+1)},&na\notin\mathbb Z\\&\frac{X_{(n\alpha)} + X_{(n\alpha+1)}}{2},&na\in\mathbb Z\\\end{aligned}\right.
$$

 называется выборочной квантилью уровня $\alpha$ для выборки $X_1,X_2,\cdots,X_n$

Квантиль уровня $0.5$ называется медианой.[/infobox]

# Точечное оценивание

## Точечное оценивание

* Пусть генеральная совокупность $\xi$ (а значит и все случайные величины $X_i, i\in\{1,\cdot,n\}$) имеют распределение Пуассона $\Pi_\lambda$ с неизвестным параметром $\lambda > 0$. Тогда $P_\theta = \Pi_\lambda, \theta = \lambda, \Theta = (0,+\infty)$.
* Пусть генеральная совокупность $\xi$ имеет распределение Бернулли $B_p$ с неизвестным параметром $p\in(0,1)$. Тогда $P_\theta = B_p,\theta=p,\Theta = (0,1)$.
* Пусть генеральная совокупность $\xi$ имеет равномерное распределение $U_{a,b}$ с неизвестными параметрами $a<b$. Тогда $P_\theta = U_{a,b},\theta = (a,b),\Theta=\{(a,b)\in\mathbb R^2:a<b\}$.
* Пусть генеральная совокупность $\xi$ имеет нормальное распределение $N_{a,1}$ с неизвестным параметром $a$. Тогда $P_\theta = N_{a,1},\theta=a,\Theta=\mathbb R$.

Отметим еще один важный момент. Предположим, что $X_1,\cdots,X_n$ – выборка объема $n$ из распределения $P_\theta$. Тогда характеристики случайных величин $X_i$ (математическое ожидание, дисперсия и проч.) зависят от параметра $\theta$.

[h2title]Точечные оценки и их свойства[/h2title]

Так как мы говорим о точечном оценивании, об оценивании неизвестных параметров, то следует для начала определить понятие оценки. Последнюю часто называют статистикой.

[infobox title="标题内容"]Пусть $X_1,\cdots,X_n$ – выборка объема $n$ из семейства распределений $P_\theta,\theta\in\Theta$. Статистикой (или оценкой) параметра $\theta$ называется произвольная функция

$$
\hat\theta=\hat\theta(X_1,\cdots,X_n)
$$

, являющаяся случайной величиной.[/infobox]

[infobox title="Несмещенность оценки"]Статистика $\hat\theta=\hat\theta(X_1,\cdots,X_n)$ называется несмещенной оценкой параметра $\theta$, если для любого $\theta\in\Theta$ справедливо равенство $E_\theta\hat\theta=\theta$.[/infobox]

[infobox title="Асимптотическая несмещенность оценки"]Статистика $\hat\theta=\hat\theta(X_1,\cdots,X_n)$ называется асимптотически несмещенной оценкой параметра $\theta$, если для любого $\theta\in\Theta$ выполняется $E_\theta\hat\theta\to\theta\quad(n\to\infty)$.[/infobox]

[infobox title="Состоятельность оценки"]Статистика $\hat\theta=\hat\theta(X_1,\cdots,X_n)$ называется состоятельной оценкой параметра $\theta$, если для любого $\theta \in \Theta$ выполняется $\hat\theta\to\theta\quad(n\to\infty)$.[/infobox]

## Метод моментов

[h2title]Метод моментов для одномерного параметра[/h2title]

Пусть $X_1,\cdots,X_n$ – выборка объема $n$ из параметрического семейства распределений $P_\theta,\theta\in\Theta\subset\mathbb R$. Пусть функция $g:\mathbb R\to\mathbb R$ такова, что существует момент

$$
E_\theta g(X_1)=f(\theta)
$$

а функция $f$ обратима на множестве $\Theta$ (напомним, что нам нужна обратимость, чтобы выразить $\theta$ через $E_\theta g(X_1)$). Разрешим выписанное соотношение относительно $\theta$ и получим

$$
\theta = f^{-1}(E_\theta g(X_1))
$$

Подставим вместо теоретического момента $E_\theta g(X_1)$ его выборочный аналог $\overline{g(X)}$, откуда получим оценку $\hat\theta$ параметра $\theta$ вида

$$
\hat\theta=f^{-1}(\overline{g(X)})=f^{-1}\left(\frac 1 n\sum_{i=1}^n g(X_i)\right)
$$

[infobox title="ОММ"]Оценка $\hat\theta$ параметра $\theta$, полученная по описанной выше схеме, называется оценсхеме, называется оценкой метода моментов (ОММ) для параметра $\theta$.[/infobox]

Чаще всего рассматривают моменты $k$-ого порядка, а потому берут функции $g(t)=t^k,k\in\{1,2,\cdots\}$. В этом случае

$$
E_\theta X_1^k=f(\theta)
$$

, и если функция $f(\theta)$ обратима, то, согласно описанной выше идее, мы приходим к соотношению

$$
\hat\theta=f^{-1}\left(\frac 1 n \sum_{i=1}^n X_i^k\right)
$$

[h2title]Состоятельность оценки метода моментов[/h2title]

[infobox title="Состоятельность ОММ"]Пусть $\hat\theta=f^{-1}(\overline{g(X)})$ – оценка параметра $\theta$, полученная по методу моментов, описанному выше, причем функция $f^{-1}$ непрерывна. Тогда оценка $\hat\theta$ состоятельна.[/infobox]

[h2title]Метод моментов для многомерного параметра[/h2title]

Todo...

## Метод максимального правдоподобия

[h2title]Модельный пример[/h2title]

Предположим, что эксперимент заключается в стрельбе по мишени из пистолета. Всего проведено 10 выстрелов, из которых 4 раза по мишени мы попали, а 6 раз промахнулись, и выборка такова (1 отвечает попаданию, 0 – промаху):

(1,0,0,1,1,0,0,0,1,0).

Как оценить вероятность попадания в мишень? В такой постановке зада- ча достаточно простая, и ответ напрашивается сразу, не так ли? Давайте попробуем применить (а заодно и объяснить) идею метода максимального правдоподобия (ММП).
Генеральная совокупность 𝜉 имеет распределение Бернулли $\xi\in B_\theta$ с параметром \theta\in\Theta=(0,1)$. Мы хотим максимизировать вероятность нашей выборки, то есть максимизировать функцию $$f_\theta(\vec X)=P_\theta(X_1=1,X_2=0,X_3=0,X_4=1,\cdots,X_{10}=0)$$

Выборка – это последовательность независимых и одинаково распределенных случайных величин, а значит

$$
f_\theta(\vec X)=P_\theta(X_1=1)\cdot P_\theta(X_2=0)\cdot P_\theta(X_3=0)\cdot P_\theta(X_4=1)\cdot\cdots\cdot P_\theta(X_{10}=0)
$$

Полученная нами функция в общем случае называется функцией правдопо- добия. Заметим, что в нашем случае, $P_\theta(X_i=0)=1-\theta, P_\theta(X_i=1)=\theta$. Значит, введенная функция преобразуется к виду

$$
f_\theta(\vec X)=\theta^4(1-\theta)^6
$$

а нашей целью становится нахождение максимума этой функции. Это можно пытаться делать «в лоб», используя аппарат дифференциального исчисления, но с произведением часто (хотя и не в этом случае) бывает «все сложно», по- этому предлагается логарифмировать (чтобы получить сумму). Логарифм – монотонная функция, поэтому экстремумы переходят в экстремумы, новых экстремумов не появляется, а старые – не теряются. Посему приходим к по- нятию логарифмической функции правдоподобия

$$
L_\theta(\vec X)=\ln f_\theta(\vec X)=4\ln\theta+6\ln(1-\theta)
$$

Полученную функцию и будем максимизировать, ведь теперь производная
берется очень просто:

$$
(L_theta(\vec X))'_\theta=\frac{4}{\theta}-\frac{6}{1-\theta}=\frac{4-10\theta}{\theta(1-\theta)}
$$

В области $\Theta = (0,1)$ лежит только одна точка, подозрительная на экстремум – это точка $\frac{4}{10}=0.4$. Используя достаточное условие экстремума стандартно проверяется, что это точка максимума. Значит, вероятность «нашей выборке случиться» максимальна при $\theta=0.4$. Удивительно? Да вовсе нет, это было понятно и с самого начала, без кучи проделанных вычислений. К сожалению, так просто бывает не всегда.

[h2title]Общее описание метода максимального правдоподобия[/h2title]

Перейдем теперь к общему описанию метода максимального правдопо- добия. На самом деле мы проделаем ровно те же выкладки, что и в примере выше, только в общем случае. Пусть $(X_1, \cdots, X_n)$ – выборка из параметрического семейства распределений $P_\theta$. Чтобы не обсуждать дискретный и непрерывный случаи отдельно, положим

$$
f_\theta=\left\{\begin{aligned}f_\theta(t)\\P_\theta(X_i=t)\end{aligned}\right.
$$

Последнее обуславливается тем, что в абсолютно непрерывном случае вероятность попадания случайной величины $\xi$ в точку (конечно равна 0) «почти равна» значению плотности в этой точке, точнее

$$
P(\xi\in(t,t+\Delta t))=\int_{\Delta t}f_\xi(t)dt\approx f_\xi(t)\Delta t
$$

Последнюю запись можно подвергнуть большой критике, но мы надеемся, что оно прольет больше понимания, а использовать мы эту «формулу» все равно не будем.

Итак, как обсуждалось ранее, мы хотим максимизировать вероятность получения нашей выборки. Так как выборка – последовательность независимых одинаково распределенных случайных величин, то возникает так называемая функция правдоподобия.

[infobox title="标题内容"]Функция

$$
f_\theta(\vec X)=f_\theta(X_1)\cdot f_\theta(X_2)\cdot \cdots \cdot f_\theta(X_n) = \prod_{i=1}^n f_\theta(X_i)
$$

 называется функцией правдоподобия.

Увидьте (!), что в случае, когда генеральная совокуп- ность имеет дискретное распределение, функция правдоподобия переписы- вается в виде

$$
f_\theta(\vec X)=P_\theta(X_1=x_1)\cdot P_\theta(X_2=x_2)\cdot \cdots \cdot P_\theta(X_n=x_n)
$$

[/infobox]

[infobox title="标题内容"]Оценкой максимального правдоподобия (ОМП) $\hat\theta$ параметра $\theta$ называется такое значение $\hat\theta\in\Theta$, при котором функция $f_{\hat\theta}(\vec X)$ достигает локального максимума.[/infobox]

Вместе с функцией правдоподобия рассмотрим так называемую логарифми- ческую функцию правдоподобия.

[infobox title="标题内容"]Функция

$$
L_\theta(\vec X)=\ln f_\theta(\vec X)=\sum_{i=1}^n \ln f_\theta(X_i)
$$

 называется логарифмической функцией правдоподобия.[/infobox]

[h2title]Примеры применения метода максимального правдоподобия[/h2title]

[infobox title="ОМП для распределения Пуассона"]Пусть $X_1,\cdots,X_n$ – выборка объема $n$ из распределения Пуассона $\Pi_theta, \theta\in\Theta=(0,+\infty)$. В нашем случае

$$
f_\theta(t)=P(X_1=t)=\frac{\theta^t}{t!}e^{-\theta},t\in\{0,1,\cdots\}
$$

Тогда функция правдоподобия принимает вид

$$
f_\theta(\vec X)=\prod_{i=1}^n f_\theta(X_i)=\prod_{i=1}^n\frac{\theta^{X_i}}{X_i!}e^{-\theta}=\frac{\theta^{X_1+X_2+\cdots+X_n}}{X_1!\cdot X_2!\cdot\cdots\cdot X_n!}e^{-n\theta}
$$

Для нахождения точек максимума, рассмотрим логарифмическую функцию правдоподобия:

$$
L_\theta(\vec X)=\ln f_\theta(\vec X)=\ln\left(\frac{\theta^{X_1+X_2+\cdots+X_n}}{X_1!\cdot X_2!\cdot\cdots\cdot X_n!}e^{-n\theta}\right)
$$

По свойствам логарифма, последнее равенство перепишем в виде

$$
\begin{aligned}L_\theta(\vec X)&=\ln \theta^{X_1+X_2+\cdots+X_n}+\ln e^{-n\theta}-\ln(X_1!\cdot X_2!\cdot \cdots \cdot X_n!)\\&=(X_1+X_2+\cdots+X_n)\ln\theta-n\theta-\ln\prod_{i=1}^n X_i!\end{aligned}
$$

Рассматриваемая нами функция дифференцируема, а значит необходимым
условием экстремума является равенство нулю производной по $\theta$. Значит, нужно решить уравнение

$$
\left(L_\theta(\vec X)\right)'_\theta = 0\ or\ \frac{X_1+X_2+\cdots+X_n}{\theta}-n=0
$$

откуда

$$
\hat\theta=\frac{X_1+X_2+\cdots+X_n}{n}=\overline X
$$

Конечно, «крышка» навешена параметру $\theta$ пока что неправомочно, ведь мы не показали, что найденная точка – это точка максимума. Это мож- но сделать, например, воспользовавшись часто называемым в литературе «вторым достаточным условием экстремума». Так как

$$
\left(L_\theta(\vec X)\right)''_\theta=-\frac{X_1+X_2+\cdots+X_n}{\theta^2}<0
$$

то можно утверждать, что $\hat\theta$ и правда является точкой максимума, а значит и крышка навешена заслуженно.

[/infobox]

[infobox title="ОМП для равномерного распределения"]Пусть $X_1,\cdots,X_n$ – выборка из равномерного распределения $U_{0,\theta}$ где $\theta\in\Theta=(0,+\infty)$. Оценим параметр $\theta$ методом максимального правдоподобия. Так как генеральная совокупность $\xi$ имеет равномерное распределение $U_{0,\theta}$, то ее плотность задается соотношением

$$
f_\xi(t)=\left\{\begin{aligned}&\frac{1}{\theta},&t\in[0,\theta]\\&0,&t\notin[0,\theta]\end{aligned}\right.
$$

Но тогда функция правдоподобия имеет вид

$$
f_\xi(\vec X)=\left\{\begin{aligned}&\frac{1}{\theta^n},&0\le X_i \le \theta, i\in\{1,\cdots,n\}\\&0\end{aligned}\right.
$$

или, что то же самое,

$$
f_\xi(\vec X)=\left\{\begin{aligned}&\frac{1}{\theta^n},&max(X_1,\cdots,X_n)=X_{(n)}\le\theta\\&0\end{aligned}\right.
$$

Из вида последней функции ясно, что ее максимум достигается при $\theta = X_{(n)}=\hat\theta$. [/infobox]

[infobox title="ОМП для нормального распределения"]Пусть $X_1,\cdots,X_n$ – выборка из нормального распределения $N_{\theta_1,\theta_2}$, где $\theta \in \Theta = \mathbb R \times (0.+\infty)$. Оценим параметр $\theta = (\theta_1,\theta_2)$ методом максимального правдоподобия. Так как генеральная совокупность $\xi$ имеет нормальное распределение $N_{\theta_1,\theta_2}$, то ее плотность задается соотношением

$$
f_\xi(t)=\frac{1}{\sqrt{2\pi\theta_2}}e^{-\frac{(t-\theta_1)^2}{2\theta_2}}
$$

Функция максимального правдоподобия задается выражением

$$
f_\theta(\vec X)=\prod_{i=1}^n\frac{1}{\sqrt{2\pi\theta_2}}e^{-\frac{(x_i-\theta_1)^2}{2\theta_2}}=\frac{1}{(2\pi\theta_2)^{\frac{n}{2}}e^{-\frac{\sum_{i=1}^n(X_i-\theta_1)^2}{2\theta_2}}}
$$

После некоторых преобразований, логарифмическая функция правдоподобия примет вид

$$
L_\theta(\vec X)=-\frac{\sum_{i=1}^n(X_i-\theta_1)^2}{2\theta_2}-\frac{n}{2}\ln(2\pi\theta_2)
$$

Необходимым условием экстремума дифференцируемой функции двух переменных является равенство нулю частных производных по всем переменным. В данном случае,

$$
\begin{aligned}&\left\{\begin{aligned}&\frac{\delta L_\theta}{\delta \theta_1}=0\\&\frac{\delta L_\theta}{\delta \theta_2}=0\end{aligned}\right.\\\Rightarrow&\left\{\begin{aligned}&\frac{\sum_{i=1}^n(X_i-\theta_1)}{\theta_2}=0\\&\frac{\sum_{i=1}^n(X_i-\theta_1)^2}{2\theta_2^2}-\frac{n}{2\theta_2}=0\end{aligned}\right.\\\Rightarrow&\left\{\begin{aligned}&\theta_1=\frac{1}{n}\sum_{i=1}^n X_i = \overline X\\&\theta_2=\frac{1}{n}\sum_{i=1}^n (X_i-\overline X)^2=S^2\end{aligned}\right.\end{aligned}
$$

Итак, если мы докажем, что в рассматриваемой точке – максимум, то можно утверждать, что $\hat\theta=(\hat\theta_1,\hat\theta_2)=(\overline X, S^2)$ – оценка максимального правдоподобия. Докажем это в замечании к данному примеру, чтобы не нагромождать идейные моменты вычислениями

В итоге, оценки максимального правдоподобия для параметров нор- мального распределения совпали с оценками метода моментов. В этом слу- чае использование метода моментов было куда проще, чем ММП.[/infobox]

[h2title]Состоятельность оценки метода максимального правдоподобия[/h2title]

[infobox title="Состоятельность ОМП"]Пусть $P_\theta$ – семейство распределений с плотностью $f_\theta(t)$, $\Theta$ – открытый интервал, возможно бесконечный, причем:

1. При каждом $\theta\in\Theta$ при всех $t\in\mathbb R$ существуют частные производные

   $$
   \frac{\delta\ln f_\theta(t)}{\delta\theta},\frac{\delta^2\ln f_\theta(t)}{\delta\theta^2},\frac{\delta^3\ln f_\theta(t)}{\delta\theta^3}
   $$
2. При каждом $\theta\in\Theta$ выполняются соотношения

   $$
   \left|\frac{\delta\ln f_\theta(t)}{\delta\theta}\right|\le F_1(t),\left|\frac{\delta^2\ln f_\theta(t)}{\delta\theta^2}\right|\le F_2(t),\left|\frac{\delta^3\ln f_\theta(t)}{\delta\theta^3}\right|\le H(t)
   $$

   где функции $F_1$ и $F_2$ интегрируемы на $\mathbb R$, а $E_\theta H(\xi)<M$, где $M$ независит от $\theta$;
3. При каждом $\theta\in\Theta$

   $$
   0<\int_{-\infty}^{+\infty}\left(\frac{\delta log f_\theta(t)}{\delta\theta}\right)^2f_\theta(t)dt<+\infty
   $$

Тогда уравнение правдоподобия $\frac{\delta L_\theta}{\delta \theta}=0$ имеет решение $\hat\theta$, причем $\hat\theta$ – состоятельная оценка параметра $\theta$.[/infobox]

# Точные и асимптотические доверительные интервалы

## Интервальное оценивание

[h2title]Точные (и не очень) доверительные интервалы[/h2title]

[infobox title="标题内容"]Пусть $0<\varepsilon<1$. Интервал

$$
(\theta^-,\theta^+)=(\theta^-(X,\varepsilon),\theta^+(X,\varepsilon))
$$

, где

$\theta^-,\theta^+$ – статистики, называется доверительным интервалом уровня доверия (или надежности) $1-\varepsilon$, если для любого $\theta\in\Theta$ выполняется

$$
P_\theta(\theta^-<\theta<\theta^+)\ge 1-\varepsilon
$$

Если в определении доверительного интервала вместо неравенства достигается равенство, то есть

$$
P_\theta(\theta^-<\theta<\theta^+)=1-\varepsilon
$$

, то доверительный интервал называется точным.

[/infobox]

[h2title]Асимптотические доверительные интервалы[/h2title]

[infobox title="标题内容"]Пусть $0<\varepsilon<1$. Интервал

$$
(\theta^-,\theta^+)=(\theta^-(X,\varepsilon))
$$

,
где $\theta^-,\theta^+$ – статистики, называется асимптотическим доверительным интервалом уровня доверия (или надежности) $1-\varepsilon$, если для любого $\theta\in\Theta$ выполняется

$$
\lim_{n\to+\infty}inf P_\theta(\theta^-<\theta<\theta^+)\ge 1-\varepsilon
$$

.[/infobox]

# Проверка гипотез


## Проверка статистических гипотез

[h2title]А что такое гипотеза?[/h2title]

[infobox title="标题内容"]Гипотезой $H$ называется произвольное предположение о распределении генеральной совокупности $\xi$.

Если же учесть только что сказанное замечание, гипотезой $H$ правильнее назвать произвольное предположение о распределении наблюдений.

Гипотеза $H$ называется простой, если она указывает только на одно распределение $H={P=P_1}$. Иначе гипотеза $H$ называется сложной $H={P\in\mathbb P}$, где $\mathbb P$ – некоторое подмножество множества всех распределений.[/infobox]

[h2title]Критерий и его ошибки[/h2title]

[infobox title="标题内容"]Пусть имеются гипотезы $H_1,H_2,\cdots,H_k$ и выборка $X=(X_1,\cdots,X_n)$. Тогда критерий $\delta=\delta(X_1,X_2,\cdots,X_n)$ – это отображение 

$$
\delta: \mathbb R^n\to \{H_1,H_2,\cdots,H_n\}
$$

Говорят, что произошла ошибка 1 рода, если гипотеза $H1$ отвергнута критерием, в то время как она верна. Говорят, что произошла ошибка 2 рода, если гипотеза $H2$ отвергнута критерием, в то время как она верна.
[/infobox]

[h2title]Уровень значимости и мощность[/h2title]

[infobox title="标题内容"]Уровнем значимости критерия $\delta$ называют вероятность ошибки первого рода $\alpha_1$: 

$$
\alpha_1=\alpha_1(\delta)=P_{H_1}(\delta\neq H_1)=P_{H_1}(\delta=H_2)=P_{H_1}(X\in S)
$$

 Итак, уровень значимости критерия – это вероятность того, что выборка попадает в критическую область в условиях того, что верна гипотеза $H1$.

Мощностью критерия $\delta$ называют $1-\alpha_2$, то есть 

$$
1-\alpha_2=1-\alpha_2(\delta)=1-P_{H_2}(\delta\neq H_2)=P_{H_2}(\delta=H_2)=P_{H_2}(X\in S)
$$

 Итак, мощность критерия – это вероятность того, что выборка попадет в критическую область при условиях того, что верна гипотеза $H2$.[/infobox]

## Критерии согласия

[h2title]Понятие критерия согласия[/h2title]

[infobox title="标题内容"]Критериями согласия обычно называют критерии, предназначенные для проверки простой гипотезы $H_1=\{P=P_1\}$ при сложной альтернативе $H2 = \{гипотеза\ H1\ неверна\}$.[/infobox]

[h2title]Критерий Колмогорова[/h2title]
